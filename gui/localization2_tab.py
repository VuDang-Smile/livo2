#!/usr/bin/env python3
"""
Localization2 Tab Module
Tab Ä‘á»ƒ Ä‘iá»u khiá»ƒn Localization2 system vá»›i FAST-LIVO2
"""

import threading
import subprocess
from pathlib import Path
from datetime import datetime
import os
import platform
import signal
import sys
import time
import tempfile
import queue
import re
import shutil
from functools import partial

# Multiprocessing for parallel downsampling
try:
    from multiprocessing import Pool, cpu_count
    HAS_MULTIPROCESSING = True
except ImportError:
    HAS_MULTIPROCESSING = False
    cpu_count = lambda: 1

# Open3D vÃ  scipy imports (optional, for map loading)
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    HAS_OPEN3D = False

try:
    from scipy.spatial.transform import Rotation
    from scipy.spatial import cKDTree
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    cKDTree = None

# ROS2 imports with graceful fallback
try:
    import rclpy
    from rclpy.node import Node
    from rclpy.executors import MultiThreadedExecutor
    from nav_msgs.msg import Odometry
    ROS2_AVAILABLE = True
except ImportError:
    print("âš ï¸  ROS2 not available. Localization2 tab will be limited.")
    ROS2_AVAILABLE = False
    # Create dummy classes for when ROS2 is not available
    class Node:
        def __init__(self, *args, **kwargs):
            pass
    class MultiThreadedExecutor:
        def __init__(self, *args, **kwargs):
            pass
    class Odometry:
        pass

try:
    import tkinter as tk
    from tkinter import ttk, messagebox, scrolledtext, filedialog
except ImportError as e:
    print(f"Lá»—i import: {e}")
    import sys
    sys.exit(1)


class LocalizationListenerNode(Node):
    """ROS2 node to listen to localization odometry topic"""
    
    def __init__(self, localization_tab):
        if not ROS2_AVAILABLE:
            return
        super().__init__('localization_listener')
        self.localization_tab = localization_tab
        
        # Subscribe to /Odometry (default topic from localization2)
        try:
            self.subscription = self.create_subscription(
                Odometry,
                '/Odometry',
                self.localization_callback,
                10  # QoS depth
            )
            self.get_logger().info('âœ… Subscribed to /Odometry topic (localization2 default)')
        except Exception as e:
            self.get_logger().error(f'Failed to subscribe to /Odometry: {e}')
    
    def localization_callback(self, msg):
        """Callback for /Odometry topic messages"""
        try:
            # Pass the message to the Localization2Tab for processing
            self.localization_tab.update_localization_data(msg)
        except Exception as e:
            if ROS2_AVAILABLE:
                self.get_logger().error(f'Error in localization callback: {e}')


class Localization2Tab(ttk.Frame):
    """Tab cho Localization2 Control"""
    
    def __init__(self, parent):
        super().__init__(parent)
        
        # Paths
        self.project_root = Path(__file__).parent.parent
        self.workspace_path = self.project_root / "ws"
        self.script_path = self.project_root / "scripts" / "start_localization2.sh"
        self.log_dir = self.workspace_path / "src" / "FAST-LIVO2" / "Log"
        
        # Processes
        self.localization_process = None
        
        # ROS2
        self.ros_node = None
        self.ros_executor = None
        self.ros_thread = None
        self.is_ros_running = False
        
        # State
        self.is_localization_running = False
        self.selected_map_dir = None
        self.map_info_loaded = False  # Flag Ä‘á»ƒ biáº¿t Ä‘Ã£ load map info chÆ°a
        
        # Map size limits (Ä‘á»ƒ trÃ¡nh crash RViz vÃ  Ä‘áº£m báº£o RViz mÆ°á»£t)
        self.max_map_points = 50_000_000  # 50M points - giá»›i háº¡n an toÃ n
        self.warning_map_points = 5_000_000  # 5M points - tá»± Ä‘á»™ng optimize (giáº£m tá»« 8M)
        self.safe_map_points = 2_000_000  # 2M points - luÃ´n optimize (giáº£m tá»« 3M)
        self.downsample_voxel_size = 0.22  # Voxel size cho downsample (m) - tÄƒng Ä‘á»ƒ downsample nhiá»u hÆ¡n (0.18 -> 0.22)
        
        # Per-file PCD limits (Ä‘á»ƒ RViz mÆ°á»£t hÆ¡n - giáº£m máº¡nh Ä‘á»ƒ downsample nhiá»u hÆ¡n)
        self.max_points_per_file = 500_000  # 500K points per file - tá»± Ä‘á»™ng downsample náº¿u vÆ°á»£t (giáº£m tá»« 800K)
        self.file_downsample_voxel_size = 0.15  # Voxel size cÆ¡ báº£n cho auto-downsample file (m) - tÄƒng (0.12 -> 0.15)
        self.target_points_per_file = 300_000  # Target points sau downsample (~300K Ä‘á»ƒ RViz ráº¥t mÆ°á»£t, giáº£m tá»« 500K)
        
        # Localization data
        self.position_var = None
        self.orientation_var = None
        self.velocity_var = None
        self.timestamp_var = None
        
        # Táº¡o UI
        self.create_widgets()
    
    def create_widgets(self):
        """Táº¡o cÃ¡c widget cho tab Localization2"""
        
        # Main container vá»›i scrollbar
        main_container = ttk.Frame(self)
        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Canvas vÃ  scrollbar
        self.canvas = tk.Canvas(main_container, highlightthickness=0)
        scrollbar = ttk.Scrollbar(main_container, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = ttk.Frame(self.canvas)
        
        # Configure scrollable frame
        def configure_scroll_region(event=None):
            self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        
        self.scrollable_frame.bind("<Configure>", configure_scroll_region)
        
        # Create window in canvas
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        
        # Configure canvas scrolling - ensure width matches canvas
        def configure_canvas_width(event):
            canvas_width = event.width
            self.canvas.itemconfig(self.canvas_window, width=canvas_width)
            # Update scroll region after width change
            self.after_idle(lambda: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        
        self.canvas.bind('<Configure>', configure_canvas_width)
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        # Mouse wheel scrolling
        def on_mousewheel(event):
            self.canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")
        
        self.canvas.bind_all("<MouseWheel>", on_mousewheel)
        
        # Pack canvas and scrollbar
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # Configure main container
        main_container.columnconfigure(0, weight=1)
        main_container.rowconfigure(0, weight=1)
        
        # Store canvas reference for later updates
        self.main_canvas = self.canvas
        
        # Map Selection Section
        self.setup_map_selection()
        
        # Control Section
        self.setup_control()
        
        # Localization Data Section
        self.setup_localization_data()
        
        # Status and Log Section
        self.setup_status_log()
        
        # Configure grid weights
        self.scrollable_frame.columnconfigure(0, weight=1)
        
        # Update canvas scroll region after all widgets are created
        self.after(100, lambda: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
    
    def setup_map_selection(self):
        """Setup map selection section"""
        map_frame = ttk.LabelFrame(self.scrollable_frame, text="Map Selection", padding="10")
        map_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(map_frame, text="Select a map directory from FAST-LIVO2 Log", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Selected map display
        self.map_dir_var = tk.StringVar(value="No map selected")
        self.map_dir_label = ttk.Label(map_frame, text="Selected map:", font=('Arial', 10))
        self.map_dir_label.grid(row=1, column=0, sticky=tk.W, pady=(0, 5))
        
        self.map_dir_display = ttk.Label(map_frame, textvariable=self.map_dir_var, 
                                         font=('Arial', 9), foreground='blue', wraplength=600)
        self.map_dir_display.grid(row=2, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Buttons
        buttons_frame = ttk.Frame(map_frame)
        buttons_frame.grid(row=3, column=0, columnspan=2, pady=(0, 5))
        
        self.select_map_button = ttk.Button(buttons_frame, text="ğŸ“ Select Map Directory", 
                                           command=self.select_map_directory)
        self.select_map_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.select_latest_button = ttk.Button(buttons_frame, text="â¬‡ï¸ Select Latest Map", 
                                               command=self.select_latest_map)
        self.select_latest_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.load_map_info_button = ttk.Button(buttons_frame, text="ğŸ“Š Load Map Info", 
                                               command=self.load_map_info)
        self.load_map_info_button.pack(side=tk.LEFT)
        
        # Map info display
        self.map_info_var = tk.StringVar(value="No map info loaded - Click 'Load Map Info' to analyze")
        self.map_info_label = ttk.Label(map_frame, textvariable=self.map_info_var, 
                                       font=('Arial', 9), foreground='green', wraplength=600, justify=tk.LEFT)
        self.map_info_label.grid(row=4, column=0, columnspan=2, sticky=tk.W, pady=(10, 5))
        
        # Configure grid weights
        map_frame.columnconfigure(0, weight=1)
    
    def setup_control(self):
        """Setup control section"""
        control_frame = ttk.LabelFrame(self.scrollable_frame, text="Localization2 Control", padding="10")
        control_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(control_frame, text="FAST_LIO_LOCALIZATION2 system for localization", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Status
        self.status_var = tk.StringVar(value="Stopped")
        self.status_label = ttk.Label(control_frame, textvariable=self.status_var, 
                                      font=('Arial', 10, 'bold'))
        self.status_label.grid(row=1, column=0, columnspan=2, pady=(0, 10))
        
        # Control buttons
        buttons_frame = ttk.Frame(control_frame)
        buttons_frame.grid(row=2, column=0, columnspan=2, pady=(0, 5))
        
        self.start_button = ttk.Button(buttons_frame, text="ğŸš€ Start Localization2", 
                                      command=self.start_localization2)
        self.start_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.stop_button = ttk.Button(buttons_frame, text="â¹ï¸ Stop Localization2", 
                                     command=self.stop_localization2, state=tk.DISABLED)
        self.stop_button.pack(side=tk.LEFT)
        
        # Configure grid weights
        control_frame.columnconfigure(0, weight=1)
    
    def setup_localization_data(self):
        """Setup localization data display section"""
        data_frame = ttk.LabelFrame(self.scrollable_frame, text="Localization Data (/Odometry)", padding="10")
        data_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(data_frame, text="Real-time pose data from /Odometry topic", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Current pose display
        current_frame = ttk.Frame(data_frame)
        current_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 5))
        
        # Position
        ttk.Label(current_frame, text="Position (x, y, z):", font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.position_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.position_var, font=('Courier', 9), foreground='blue').grid(row=0, column=1, sticky=tk.W)
        
        # Orientation
        ttk.Label(current_frame, text="Orientation (x, y, z, w):", font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, padx=(0, 10))
        self.orientation_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.orientation_var, font=('Courier', 9), foreground='blue').grid(row=1, column=1, sticky=tk.W)
        
        # Velocity
        ttk.Label(current_frame, text="Velocity (x, y, z):", font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, padx=(0, 10))
        self.velocity_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.velocity_var, font=('Courier', 9), foreground='blue').grid(row=2, column=1, sticky=tk.W)
        
        # Timestamp
        ttk.Label(current_frame, text="Last Update:", font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, padx=(0, 10))
        self.timestamp_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.timestamp_var, font=('Courier', 9), foreground='green').grid(row=3, column=1, sticky=tk.W)
        
        # Configure grid weights
        data_frame.columnconfigure(0, weight=1)
        current_frame.columnconfigure(1, weight=1)
    
    def setup_status_log(self):
        """Setup status and log section"""
        log_frame = ttk.LabelFrame(self.scrollable_frame, text="Status & Log", padding="10")
        log_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        # Create text widget with scrollbar
        self.log_text = tk.Text(log_frame, height=15, wrap=tk.WORD, font=('Courier', 9))
        log_scrollbar = ttk.Scrollbar(log_frame, orient="vertical", command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=log_scrollbar.set)
        
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        log_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        # Clear log button
        self.clear_log_button = ttk.Button(log_frame, text="ğŸ—‘ï¸ Clear Log", 
                                          command=self.clear_log)
        self.clear_log_button.grid(row=1, column=0, sticky=tk.W, pady=(5, 0))
        
        # Configure grid weights
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        
        # Update canvas scroll region after adding log frame
        self.after_idle(lambda: self.main_canvas.configure(scrollregion=self.main_canvas.bbox("all")))
    
    def find_latest_map_directory(self):
        """TÃ¬m map directory má»›i nháº¥t trong Log/ cÃ³ dá»¯ liá»‡u"""
        if not self.log_dir.exists():
            return None
        
        map_dirs = sorted(self.log_dir.glob("map_*"), key=lambda x: x.name, reverse=True)
        
        # TÃ¬m map Ä‘áº§u tiÃªn cÃ³ dá»¯ liá»‡u (cÃ³ PCD files hoáº·c pose.json cÃ³ ná»™i dung)
        for map_dir in map_dirs:
            if self.is_map_valid(map_dir):
                return map_dir
        
        return None
    
    def _check_pcd_format(self, pcd_file_path):
        """
        Kiá»ƒm tra format cá»§a PCD file (cÃ³ RGB hay khÃ´ng)
        Returns: True náº¿u cÃ³ RGB, False náº¿u khÃ´ng
        """
        try:
            # Äá»c header cá»§a PCD file Ä‘á»ƒ kiá»ƒm tra format
            with open(pcd_file_path, 'rb') as f:
                header = f.read(2048).decode('utf-8', errors='ignore')
                # Kiá»ƒm tra xem cÃ³ FIELDS chá»©a rgb hoáº·c rgba khÃ´ng
                if 'FIELDS' in header:
                    fields_line = [line for line in header.split('\n') if 'FIELDS' in line]
                    if fields_line:
                        fields = fields_line[0].upper()
                        # Kiá»ƒm tra cÃ³ rgb hoáº·c rgba trong FIELDS
                        if 'RGB' in fields or 'RGBA' in fields:
                            return True
        except:
            pass
        return False
    
    def _read_pcd_with_auto_downsample(self, pcd_file_path, preserve_colors=True):
        """
        Äá»c PCD file vá»›i tá»± Ä‘á»™ng downsample náº¿u quÃ¡ lá»›n
        Äáº£m báº£o Ä‘á»c Ä‘Ãºng dá»¯ liá»‡u Ä‘Ã£ quÃ©t (colors, normals náº¿u cÃ³)
        Voxel size Ä‘Æ°á»£c tÃ­nh Ä‘á»™ng: cÃ ng nhiá»u points â†’ downsample cÃ ng nhiá»u
        
        Args:
            pcd_file_path: Path Ä‘áº¿n PCD file
            preserve_colors: CÃ³ giá»¯ colors khÃ´ng (default: True)
            
        Returns:
            tuple: (point_cloud, was_downsampled, voxel_size_used)
                - point_cloud: Point cloud Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ (downsample náº¿u cáº§n)
                - was_downsampled: True náº¿u Ä‘Ã£ downsample, False náº¿u khÃ´ng
                - voxel_size_used: Voxel size Ä‘Ã£ sá»­ dá»¥ng (None náº¿u khÃ´ng downsample)
        """
        if not HAS_OPEN3D:
            return None, False
        
        try:
            # Kiá»ƒm tra format PCD file trÆ°á»›c khi Ä‘á»c
            has_rgb_in_file = self._check_pcd_format(pcd_file_path)
            
            # Äá»c PCD file (open3d tá»± Ä‘á»™ng detect format vÃ  preserve colors/normals)
            # KhÃ´ng cáº§n chá»‰ Ä‘á»‹nh format='auto' vÃ¬ Ä‘Ã³ lÃ  default
            pcd = o3d.io.read_point_cloud(str(pcd_file_path))
            
            if len(pcd.points) == 0:
                return None, False, None
            
            num_points = len(pcd.points)
            was_downsampled = False
            voxel_size_used = None
            
            # Kiá»ƒm tra xem colors cÃ³ Ä‘Æ°á»£c Ä‘á»c Ä‘Ãºng khÃ´ng
            has_colors_after_read = pcd.has_colors()
            if has_rgb_in_file and not has_colors_after_read:
                # File cÃ³ RGB nhÆ°ng khÃ´ng Ä‘á»c Ä‘Æ°á»£c - cÃ³ thá»ƒ lÃ  format issue
                # Thá»­ Ä‘á»c láº¡i vá»›i format cá»¥ thá»ƒ
                try:
                    # Thá»­ Ä‘á»c vá»›i format PCD (khÃ´ng chá»‰ Ä‘á»‹nh format cá»¥ thá»ƒ)
                    pcd = o3d.io.read_point_cloud(str(pcd_file_path))
                    has_colors_after_read = pcd.has_colors()
                except:
                    pass
            
            # Kiá»ƒm tra náº¿u file quÃ¡ lá»›n, tá»± Ä‘á»™ng downsample
            if num_points > self.max_points_per_file:
                import numpy as np
                
                # Kiá»ƒm tra vÃ  preserve colors
                has_colors = pcd.has_colors()
                has_normals = pcd.has_normals()
                
                # LÆ°u colors gá»‘c trÆ°á»›c khi xá»­ lÃ½ (Ä‘á»ƒ Ä‘áº£m báº£o khÃ´ng máº¥t dá»¯ liá»‡u)
                original_colors = None
                if has_colors:
                    original_colors = np.asarray(pcd.colors).copy()
                    # Open3D lÆ°u colors trong range 0-1, nhÆ°ng PCD file cÃ³ thá»ƒ lÃ  0-255
                    # Kiá»ƒm tra xem colors cÃ³ trong range nÃ o
                    colors = np.asarray(pcd.colors)
                    # Náº¿u colors > 1.0, cÃ³ thá»ƒ lÃ  Ä‘Ã£ Ä‘Æ°á»£c normalize sai hoáº·c format khÃ¡c
                    # Chá»‰ normalize náº¿u thá»±c sá»± cáº§n (colors > 1.0 vÃ  cÃ³ váº» nhÆ° lÃ  0-255)
                    if colors.max() > 1.0 and colors.max() <= 255.0:
                        # Normalize tá»« 0-255 vá» 0-1 (open3d format)
                        pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
                    # Náº¿u colors Ä‘Ã£ trong range 0-1, giá»¯ nguyÃªn
                
                # TÃ­nh toÃ¡n voxel size Ä‘á»™ng dá»±a trÃªn sá»‘ points
                # CÃ ng nhiá»u points thÃ¬ downsample cÃ ng nhiá»u (voxel size lá»›n hÆ¡n)
                # Voxel downsample giáº£m points theo volume (tá»· lá»‡ vá»›i voxel_size^3)
                # CÃ´ng thá»©c: voxel_size = base_size * (num_points / target_points)^(1/3)
                reduction_ratio = num_points / self.target_points_per_file
                # Cube root Ä‘á»ƒ tÃ­nh voxel size (vÃ¬ volume tá»· lá»‡ vá»›i size^3)
                dynamic_voxel_size = self.file_downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                
                # Giá»›i háº¡n voxel size trong khoáº£ng há»£p lÃ½ (0.05m - 0.5m)
                dynamic_voxel_size = max(0.05, min(0.5, dynamic_voxel_size))
                voxel_size_used = dynamic_voxel_size
                
                # Downsample vá»›i voxel size Ä‘á»™ng (cÃ ng nhiá»u points â†’ voxel size cÃ ng lá»›n â†’ downsample cÃ ng nhiá»u)
                if preserve_colors:
                    # Voxel downsample tá»± Ä‘á»™ng preserve colors
                    pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                else:
                    pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                
                # Äáº£m báº£o colors Ä‘Æ°á»£c preserve sau downsample
                if has_colors and not pcd.has_colors():
                    # Náº¿u máº¥t colors sau downsample (hiáº¿m khi xáº£y ra vá»›i open3d)
                    # KhÃ´i phá»¥c tá»« original_colors Ä‘Ã£ lÆ°u
                    if HAS_SCIPY and cKDTree and original_colors is not None:
                        # Äá»c láº¡i file gá»‘c Ä‘á»ƒ láº¥y points gá»‘c
                        original_pcd = o3d.io.read_point_cloud(str(pcd_file_path), format='auto')
                        original_points = np.asarray(original_pcd.points)
                        downsampled_points = np.asarray(pcd.points)
                        
                        # TÃ¬m colors gáº§n nháº¥t tá»« original
                        tree = cKDTree(original_points)
                        _, indices = tree.query(downsampled_points, k=1)
                        downsampled_colors = original_colors[indices]
                        pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                    elif original_colors is not None:
                        # Fallback: sá»­ dá»¥ng colors trung bÃ¬nh náº¿u khÃ´ng cÃ³ scipy
                        # (khÃ´ng lÃ½ tÆ°á»Ÿng nhÆ°ng tá»‘t hÆ¡n khÃ´ng cÃ³ colors)
                        import numpy as np
                        avg_color = np.mean(original_colors, axis=0)
                        downsampled_colors = np.tile(avg_color, (len(pcd.points), 1))
                        pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                
                was_downsampled = True
                
            return pcd, was_downsampled, voxel_size_used
            
        except Exception as e:
            import traceback
            # Log lá»—i chi tiáº¿t Ä‘á»ƒ debug
            print(f"Error reading PCD file {pcd_file_path}: {e}")
            print(traceback.format_exc())
            return None, False, None
    
    def is_map_valid(self, map_dir):
        """Kiá»ƒm tra map directory cÃ³ dá»¯ liá»‡u há»£p lá»‡ khÃ´ng (giá»‘ng pcd_viewer_tab.py)"""
        if not map_dir.exists():
            return False
        
        # Kiá»ƒm tra cÃ³ pose.json
        pose_file = map_dir / "pose.json"
        if not pose_file.exists():
            return False
        
        # Kiá»ƒm tra pose.json cÃ³ ná»™i dung (khÃ´ng rá»—ng)
        try:
            if pose_file.stat().st_size == 0:
                return False
            
            # Äá»c vÃ  validate pose.json cÃ³ Ã­t nháº¥t 1 pose há»£p lá»‡ (giá»‘ng pcd_viewer_tab.py)
            poses_found = 0
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    # Format: tx ty tz w x y z (7 values)
                    if len(parts) >= 7:
                        try:
                            # Validate cÃ³ thá»ƒ parse Ä‘Æ°á»£c
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses_found += 1
                            # Chá»‰ cáº§n 1 pose há»£p lá»‡ lÃ  Ä‘á»§
                            if poses_found >= 1:
                                break
                        except ValueError:
                            continue
            
            if poses_found == 0:
                return False
                
        except Exception:
            return False
        
        # Kiá»ƒm tra cÃ³ pcd directory vÃ  cÃ³ Ã­t nháº¥t 1 PCD file
        pcd_dir = map_dir / "pcd"
        if pcd_dir.exists():
            pcd_files = list(pcd_dir.glob("*.pcd"))
            if len(pcd_files) > 0:
                return True
        
        # Náº¿u khÃ´ng cÃ³ PCD files nhÆ°ng pose.json cÃ³ ná»™i dung há»£p lá»‡, váº«n coi lÃ  valid
        # (cÃ³ thá»ƒ lÃ  single file map hoáº·c map Ä‘ang Ä‘Æ°á»£c táº¡o)
        return True
    
    def select_latest_map(self):
        """Chá»n map má»›i nháº¥t cÃ³ dá»¯ liá»‡u"""
        latest_map = self.find_latest_map_directory()
        if latest_map:
            self.selected_map_dir = str(latest_map)
            self.map_dir_var.set(self.selected_map_dir)
            
            # Äá»c vÃ  hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t vá» map (giá»‘ng pcd_viewer_tab.py)
            try:
                pose_file = latest_map / "pose.json"
                poses_count = 0
                if pose_file.exists():
                    with open(pose_file, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            parts = line.split()
                            if len(parts) >= 7:
                                try:
                                    float(parts[0]), float(parts[1]), float(parts[2])
                                    float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                                    poses_count += 1
                                except ValueError:
                                    continue
                
                pcd_count = len(list((latest_map / "pcd").glob("*.pcd"))) if (latest_map / "pcd").exists() else 0
                self.log_message(f"âœ… Selected latest valid map: {latest_map.name}")
                self.log_message(f"   ğŸ“„ {poses_count} poses in pose.json")
                if pcd_count > 0:
                    self.log_message(f"   ğŸ“¦ {pcd_count} PCD tiles found")
                else:
                    self.log_message(f"   âš ï¸ No PCD tiles found (using pose.json only)")
                
                # Reset map info khi chá»n map má»›i
                self.map_info_loaded = False
                self.map_info_var.set(f"Map: {latest_map.name} | {poses_count} poses | {pcd_count} tiles - Click 'Load Map Info' for details")
            except Exception as e:
                self.log_message(f"âœ… Selected latest valid map: {latest_map.name}")
                self.log_message(f"   âš ï¸ Could not read map details: {e}")
                self.map_info_loaded = False
                self.map_info_var.set("No map info loaded - Click 'Load Map Info' to analyze")
        else:
            messagebox.showwarning("Warning", "No valid map directories found in Log/\n(Maps must have pose.json with content)")
            self.log_message("âš ï¸ No valid map directories found")
    
    def select_map_directory(self):
        """Chá»n map directory"""
        initial_dir = str(self.log_dir) if self.log_dir.exists() else str(self.project_root)
        selected = filedialog.askdirectory(
            title="Select Map Directory",
            initialdir=initial_dir
        )
        
        if selected:
            # Check if it's a valid map directory
            map_path = Path(selected)
            if (map_path / "pose.json").exists() or (map_path / "pcd").exists():
                self.selected_map_dir = selected
                self.map_dir_var.set(self.selected_map_dir)
                self.log_message(f"âœ… Selected map: {map_path.name}")
                # Reset map info khi chá»n map má»›i
                self.map_info_loaded = False
                self.map_info_var.set("No map info loaded - Click 'Load Map Info' to analyze")
            else:
                messagebox.showwarning("Warning", "Selected directory doesn't appear to be a valid map directory.\nLooking for pose.json or pcd/ subdirectory.")
                self.log_message("âš ï¸ Invalid map directory selected")
    
    def log_message(self, message):
        """ThÃªm message vÃ o log"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
    
    def load_map_info(self):
        """Load vÃ  hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t vá» map (giá»‘ng pcd_viewer_tab.py)"""
        if not self.selected_map_dir:
            messagebox.showwarning("Warning", "Please select a map directory first!")
            return
        
        map_path = Path(self.selected_map_dir)
        if not map_path.exists():
            messagebox.showerror("Error", "Selected map directory does not exist!")
            return
        
        # Load map info trong thread riÃªng Ä‘á»ƒ khÃ´ng block UI
        threading.Thread(target=self._load_map_info_worker, args=(str(map_path),), daemon=True).start()
    
    def _load_map_info_worker(self, map_dir_path):
        """Worker thread Ä‘á»ƒ load map info"""
        try:
            map_info = self.load_map_tiles_info(map_dir_path)
            if map_info:
                # Update UI trong main thread
                def update_ui():
                    self.map_info_var.set(
                        f"Map: {map_info['name']}\n"
                        f"Tiles: {map_info['loaded_count']}/{map_info['total_poses']}\n"
                        f"Total Points: {map_info['total_points']:,}\n"
                        f"Failed: {map_info['failed_count']}"
                    )
                    self.map_info_loaded = True
                self.after(0, update_ui)
        except Exception as e:
            self.log_message(f"âŒ Error loading map info: {e}")
            def update_error():
                self.map_info_var.set(f"Error loading map info: {e}")
            self.after(0, update_error)
    
    def load_map_tiles_info(self, map_dir_path):
        """Load vÃ  tÃ­nh toÃ¡n thÃ´ng tin vá» map tiles (tÃ­ch há»£p tá»« Recorder project)
        
        CÃ¡ch Ä‘á»c tiles PCD (tá»« Recorder):
        1. Äá»c pose.json Ä‘á»ƒ láº¥y danh sÃ¡ch poses vÃ  file_index
        2. Sá»­ dá»¥ng glob Ä‘á»ƒ tÃ¬m táº¥t cáº£ PCD files trong pcd/ directory (validation)
        3. Äá»c tá»«ng PCD file theo file_index: pcd_dir / f"{file_index}.pcd"
        4. Validate sá»‘ lÆ°á»£ng PCD files khá»›p vá»›i sá»‘ poses
        """
        if not HAS_OPEN3D:
            self.log_message("âš ï¸ open3d khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t. KhÃ´ng thá»ƒ load map info chi tiáº¿t.")
            self.log_message("ğŸ’¡ CÃ i Ä‘áº·t: pip3 install open3d")
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists():
            self.log_message(f"âŒ KhÃ´ng tÃ¬m tháº¥y pose.json táº¡i: {pose_file}")
            return None
        
        if not pcd_dir.exists():
            self.log_message(f"âŒ KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c pcd/ táº¡i: {pcd_dir}")
            return None
        
        self.log_message(f"ğŸ“‚ Äang load map info tá»«: {map_dir.name}")
        self.log_message(f"ğŸ“„ Äá»c pose.json...")
        
        # Äá»c pose.json
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            self.log_message(f"âŒ Lá»—i khi Ä‘á»c pose.json: {e}")
            return None
        
        if not poses:
            self.log_message("âŒ KhÃ´ng cÃ³ pose nÃ o trong pose.json")
            return None
        
        self.log_message(f"ğŸ“Š TÃ¬m tháº¥y {len(poses)} poses")
        
        # Validation: Sá»­ dá»¥ng glob Ä‘á»ƒ tÃ¬m táº¥t cáº£ PCD files (cÃ¡ch cá»§a Recorder)
        pcd_files_glob = list(pcd_dir.glob("*.pcd"))
        pcd_files_count = len(pcd_files_glob)
        self.log_message(f"ğŸ“¦ TÃ¬m tháº¥y {pcd_files_count} file PCD trong thÆ° má»¥c pcd/ (glob)")
        
        # Cáº£nh bÃ¡o náº¿u sá»‘ lÆ°á»£ng khÃ´ng khá»›p
        if pcd_files_count != len(poses):
            self.log_message(f"âš ï¸  Sá»‘ lÆ°á»£ng PCD files ({pcd_files_count}) khÃ´ng khá»›p vá»›i sá»‘ poses ({len(poses)})")
            self.log_message(f"   Sáº½ Ä‘á»c theo file_index tá»« pose.json (0.pcd, 1.pcd, ...)")
        
        self.log_message(f"ğŸ“¦ Äang Ä‘á»c thÃ´ng tin tá»« {len(poses)} PCD files...")
        
        # Äá»c thÃ´ng tin tá»« cÃ¡c PCD files theo file_index (giá»‘ng Recorder)
        # Recorder sá»­ dá»¥ng: pcd_dir / f"{file_index}.pcd"
        total_points = 0
        loaded_count = 0
        failed_count = 0
        downsampled_count = 0
        missing_files = []
        
        for file_index, (tx, ty, tz, w, x, y, z) in enumerate(poses):
            # CÃ¡ch Ä‘á»c tiles tá»« Recorder: sá»­ dá»¥ng file_index Ä‘á»ƒ táº¡o path
            pcd_file = pcd_dir / f"{file_index}.pcd"
            
            if not pcd_file.exists():
                failed_count += 1
                missing_files.append(file_index)
                continue
            
            try:
                # Äá»c PCD file vá»›i auto-downsample náº¿u cáº§n
                pcd, was_downsampled, voxel_size = self._read_pcd_with_auto_downsample(pcd_file, preserve_colors=True)
                
                if pcd is None or len(pcd.points) == 0:
                    failed_count += 1
                    continue
                
                num_points = len(pcd.points)
                total_points += num_points
                loaded_count += 1
                
                if was_downsampled:
                    downsampled_count += 1
                
                # Progress indicator
                if loaded_count % 50 == 0 or loaded_count == len(poses):
                    status = f" (auto-downsampled: {downsampled_count})" if downsampled_count > 0 else ""
                    self.log_message(f"  ğŸ“¦ ÄÃ£ Ä‘á»c {loaded_count}/{len(poses)} tiles, {total_points:,} points{status}...")
                    
            except Exception as e:
                failed_count += 1
                if failed_count <= 5:  # Chá»‰ log 5 lá»—i Ä‘áº§u tiÃªn
                    self.log_message(f"  âš ï¸  Lá»—i khi Ä‘á»c {pcd_file.name}: {e}")
                continue
        
        if loaded_count == 0:
            self.log_message("âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c tile nÃ o")
            return None
        
        if failed_count > 0:
            self.log_message(f"âš ï¸  {failed_count} tiles khÃ´ng Ä‘á»c Ä‘Æ°á»£c")
            if missing_files and len(missing_files) <= 10:
                self.log_message(f"   Missing files: {missing_files[:10]}{'...' if len(missing_files) > 10 else ''}")
        
        if downsampled_count > 0:
            self.log_message(f"âœ… ÄÃ£ Ä‘á»c {loaded_count} tiles, tá»•ng {total_points:,} points")
            self.log_message(f"   ğŸ“‰ {downsampled_count} files Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng downsample (> {self.max_points_per_file:,} points/file)")
        else:
            self.log_message(f"âœ… ÄÃ£ Ä‘á»c {loaded_count} tiles, tá»•ng {total_points:,} points")
        
        return {
            'name': map_dir.name,
            'total_poses': len(poses),
            'loaded_count': loaded_count,
            'failed_count': failed_count,
            'total_points': total_points,
            'downsampled_count': downsampled_count,
            'pcd_files_found': pcd_files_count  # ThÃªm thÃ´ng tin vá» sá»‘ PCD files tÃ¬m Ä‘Æ°á»£c báº±ng glob
        }
    
    def clear_log(self):
        """XÃ³a log"""
        self.log_text.delete(1.0, tk.END)
    
    def start_localization2(self):
        """Start Localization2"""
        if not self.selected_map_dir:
            messagebox.showerror("Error", "Please select a map directory first!")
            return
        
        if not os.path.exists(self.selected_map_dir):
            messagebox.showerror("Error", "Selected map directory does not exist!")
            return
        
        # Validate map directory
        map_path = Path(self.selected_map_dir)
        if not self.is_map_valid(map_path):
            messagebox.showerror("Error", 
                f"Selected map directory is invalid or empty!\n\n"
                f"Map must have:\n"
                f"  - pose.json file with content\n"
                f"  - pcd/ directory with .pcd files (optional but recommended)\n\n"
                f"Please select a valid map directory.")
            self.log_message(f"âŒ Invalid map directory: {map_path.name}")
            self.log_message("   Map must have pose.json with content and optionally PCD files")
            return
        
        # Check if script exists
        if not self.script_path.exists():
            messagebox.showerror("Error", f"Start script not found: {self.script_path}")
            self.log_message(f"âŒ Script not found: {self.script_path}")
            return
        
        self.log_message("Starting Localization2...")
        self.log_message(f"Map directory: {self.selected_map_dir}")
        
        # Update UI
        self.start_button.config(state=tk.DISABLED)
        self.stop_button.config(state=tk.NORMAL)
        self.status_var.set("Starting...")
        self.is_localization_running = True
        
        # Check map size vÃ  downsample náº¿u cáº§n (trong thread riÃªng Ä‘á»ƒ khÃ´ng block UI)
        def start_thread():
            # Kiá»ƒm tra vÃ  downsample map náº¿u cáº§n
            map_dir_to_use = self._check_and_downsample_map_if_needed()
            if not map_dir_to_use:
                self.log_message("âŒ Failed to prepare map for localization")
                self._reset_ui_state()
                return
            
            # Start localization vá»›i map Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
            self._start_localization2_with_map(map_dir_to_use)
        
        threading.Thread(target=start_thread, daemon=True).start()
    
    def _check_and_downsample_map_if_needed(self):
        """Kiá»ƒm tra kÃ­ch thÆ°á»›c map vÃ  downsample náº¿u cáº§n"""
        map_path = Path(self.selected_map_dir)
        
        # Kiá»ƒm tra map info Ä‘Ã£ Ä‘Æ°á»£c load chÆ°a
        if not self.map_info_loaded:
            self.log_message("ğŸ“Š Äang kiá»ƒm tra kÃ­ch thÆ°á»›c map...")
            map_info = self.load_map_tiles_info(str(map_path))
            if not map_info:
                self.log_message("âš ï¸ KhÃ´ng thá»ƒ Ä‘á»c map info, tiáº¿p tá»¥c vá»›i map gá»‘c")
                return str(map_path)
            
            total_points = map_info['total_points']
        else:
            # Láº¥y thÃ´ng tin tá»« map_info_var náº¿u Ä‘Ã£ load
            # Parse tá»« map_info_var Ä‘á»ƒ láº¥y total_points
            map_info_text = self.map_info_var.get()
            try:
                # TÃ¬m "Total Points: X,XXX,XXX" trong text
                match = re.search(r'Total Points: ([\d,]+)', map_info_text)
                if match:
                    total_points = int(match.group(1).replace(',', ''))
                else:
                    # Náº¿u khÃ´ng parse Ä‘Æ°á»£c, load láº¡i
                    map_info = self.load_map_tiles_info(str(map_path))
                    if not map_info:
                        return str(map_path)
                    total_points = map_info['total_points']
            except:
                # Náº¿u parse lá»—i, load láº¡i
                map_info = self.load_map_tiles_info(str(map_path))
                if not map_info:
                    return str(map_path)
                total_points = map_info['total_points']
        
        self.log_message(f"ğŸ“Š Map cÃ³ {total_points:,} points")
        
        # Kiá»ƒm tra náº¿u map quÃ¡ náº·ng
        if total_points > self.max_map_points:
            self.log_message(f"âš ï¸ Map quÃ¡ náº·ng ({total_points:,} points > {self.max_map_points:,})")
            self.log_message("ğŸ“‰ Tá»± Ä‘á»™ng downsample map Ä‘á»ƒ trÃ¡nh crash RViz...")
            
            downsampled_map_dir = self.downsample_map_tiles(str(map_path), total_map_points=total_points)
            if downsampled_map_dir:
                self.log_message(f"âœ… ÄÃ£ downsample map thÃ nh cÃ´ng")
                return downsampled_map_dir
            else:
                self.log_message("âš ï¸ KhÃ´ng thá»ƒ downsample map, tiáº¿p tá»¥c vá»›i map gá»‘c (cÃ³ thá»ƒ crash RViz)")
                return str(map_path)
        elif total_points > self.warning_map_points:
            # Map > 5M points - tá»± Ä‘á»™ng optimize Ä‘á»ƒ trÃ¡nh lag RViz
            self.log_message(f"âš ï¸ Map khÃ¡ náº·ng ({total_points:,} points > {self.warning_map_points:,})")
            self.log_message("ğŸ“‰ Tá»± Ä‘á»™ng downsample toÃ n bá»™ map Ä‘á»ƒ RViz mÆ°á»£t hÆ¡n...")
            
            # Tá»± Ä‘á»™ng downsample map vá»›i voxel size Ä‘á»™ng (khÃ´ng há»i user Ä‘á»ƒ trÃ¡nh giÃ¡n Ä‘oáº¡n)
            downsampled_map_dir = self.downsample_map_tiles(str(map_path), total_map_points=total_points)
            if downsampled_map_dir:
                self.log_message(f"âœ… ÄÃ£ downsample map thÃ nh cÃ´ng")
                return downsampled_map_dir
            else:
                self.log_message("âš ï¸ KhÃ´ng thá»ƒ downsample map, tiáº¿p tá»¥c vá»›i map gá»‘c")
        elif total_points > self.safe_map_points:
            # Map 2M-5M points - váº«n cÃ³ thá»ƒ lag, nÃªn optimize táº¥t cáº£ files
            self.log_message(f"â„¹ï¸ Map cÃ³ {total_points:,} points (cÃ³ thá»ƒ gÃ¢y lag nháº¹)")
            self.log_message("ğŸ“‰ Tá»± Ä‘á»™ng optimize táº¥t cáº£ files Ä‘á»ƒ RViz mÆ°á»£t hÆ¡n...")
        
        # LuÃ´n kiá»ƒm tra vÃ  auto-downsample cÃ¡c file PCD quÃ¡ lá»›n
        # Äá»ƒ Ä‘áº£m báº£o RViz mÆ°á»£t khi Ä‘á»c tá»«ng file (ngay cáº£ khi tá»•ng map < 10M)
        # Truyá»n total_points Ä‘á»ƒ náº¿u map > safe_map_points, downsample táº¥t cáº£ files
        optimized_map_dir = self._auto_downsample_large_files(str(map_path), total_map_points=total_points)
        if optimized_map_dir:
            return optimized_map_dir
        
        # Map OK, sá»­ dá»¥ng map gá»‘c
        return str(map_path)
    
    def _auto_downsample_large_files(self, map_dir_path, total_map_points=None):
        """
        Tá»± Ä‘á»™ng downsample cÃ¡c file PCD quÃ¡ lá»›n (> max_points_per_file) 
        hoáº·c táº¥t cáº£ cÃ¡c file náº¿u tá»•ng map > safe_map_points
        Ä‘á»ƒ Ä‘áº£m báº£o RViz mÆ°á»£t khi cháº¡y Localization2
        
        CÃ¡ch Ä‘á»c tiles PCD (tÃ­ch há»£p tá»« Recorder):
        - Äá»c pose.json Ä‘á»ƒ láº¥y file_index
        - Sá»­ dá»¥ng file_index Ä‘á»ƒ táº¡o path: pcd_dir / f"{file_index}.pcd"
        
        Args:
            map_dir_path: Path Ä‘áº¿n map directory
            total_map_points: Tá»•ng sá»‘ points cá»§a map (náº¿u biáº¿t trÆ°á»›c)
        
        Returns:
            str: Path Ä‘áº¿n map directory Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ (náº¿u cÃ³ file cáº§n downsample)
                 None náº¿u khÃ´ng cÃ³ file nÃ o cáº§n downsample
        """
        if not HAS_OPEN3D:
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists() or not pcd_dir.exists():
            return None
        
        # Äá»c pose.json Ä‘á»ƒ biáº¿t cÃ¡c file cáº§n kiá»ƒm tra (cÃ¡ch cá»§a Recorder)
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            return None
        
        # Náº¿u tá»•ng map > safe_map_points, downsample táº¥t cáº£ cÃ¡c file (khÃ´ng chá»‰ file lá»›n)
        should_downsample_all = total_map_points and total_map_points > self.safe_map_points
        
        # Kiá»ƒm tra tá»«ng file PCD theo file_index (cÃ¡ch cá»§a Recorder)
        large_files = []
        total_points_checked = 0
        for file_index, _ in enumerate(poses):
            # CÃ¡ch Ä‘á»c tiles tá»« Recorder: sá»­ dá»¥ng file_index Ä‘á»ƒ táº¡o path
            pcd_file = pcd_dir / f"{file_index}.pcd"
            if not pcd_file.exists():
                continue
            
            try:
                # Äá»c nhanh Ä‘á»ƒ kiá»ƒm tra sá»‘ points
                pcd = o3d.io.read_point_cloud(str(pcd_file))
                num_points = len(pcd.points)
                total_points_checked += num_points
                
                # Náº¿u tá»•ng map lá»›n, downsample táº¥t cáº£ cÃ¡c file
                # Hoáº·c náº¿u file riÃªng láº» quÃ¡ lá»›n, downsample file Ä‘Ã³
                if should_downsample_all or num_points > self.max_points_per_file:
                    large_files.append((file_index, pcd_file, num_points))
            except:
                continue
        
        # Náº¿u khÃ´ng cÃ³ file nÃ o cáº§n xá»­ lÃ½, khÃ´ng cáº§n optimize
        if not large_files:
            return None
        
        # CÃ³ file cáº§n xá»­ lÃ½, táº¡o báº£n copy Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
        if should_downsample_all:
            self.log_message(f"ğŸ“‰ Map cÃ³ {total_map_points:,} points > {self.safe_map_points:,}")
            self.log_message(f"   Tá»± Ä‘á»™ng downsample táº¥t cáº£ {len(large_files)} files Ä‘á»ƒ RViz mÆ°á»£t hÆ¡n...")
        else:
            self.log_message(f"ğŸ“‰ PhÃ¡t hiá»‡n {len(large_files)} file PCD quÃ¡ lá»›n (> {self.max_points_per_file:,} points/file)")
            self.log_message("   Tá»± Ä‘á»™ng downsample cÃ¡c file nÃ y Ä‘á»ƒ RViz mÆ°á»£t hÆ¡n...")
        
        # Táº¡o thÆ° má»¥c optimized map
        temp_dir = Path(tempfile.gettempdir()) / "localization2_optimized"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        optimized_map_dir = temp_dir / f"{map_dir.name}_optimized"
        optimized_map_dir.mkdir(exist_ok=True)
        optimized_pcd_dir = optimized_map_dir / "pcd"
        optimized_pcd_dir.mkdir(exist_ok=True)
        
        # Copy pose.json
        shutil.copy2(pose_file, optimized_map_dir / "pose.json")
        
        # Xá»­ lÃ½ tá»«ng file
        processed_count = 0
        for file_index, original_pcd_file, original_points in large_files:
            try:
                # Äá»c vÃ  auto-downsample file (voxel size Ä‘á»™ng dá»±a trÃªn sá»‘ points)
                pcd, was_downsampled, voxel_size = self._read_pcd_with_auto_downsample(original_pcd_file, preserve_colors=True)
                
                if pcd is None:
                    # Copy file gá»‘c náº¿u khÃ´ng Ä‘á»c Ä‘Æ°á»£c
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                    continue
                
                # LÆ°u file Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½
                # Äáº£m báº£o colors Ä‘Æ°á»£c lÆ°u Ä‘Ãºng format (PointXYZRGB náº¿u cÃ³ colors)
                output_file = optimized_pcd_dir / f"{file_index}.pcd"
                # Open3D tá»± Ä‘á»™ng detect format dá»±a trÃªn cÃ³ colors hay khÃ´ng
                # write_ascii=False: lÆ°u binary format (nhanh hÆ¡n, nhá» hÆ¡n)
                # compressed=False: khÃ´ng nÃ©n Ä‘á»ƒ Ä‘áº£m báº£o tÆ°Æ¡ng thÃ­ch tá»‘t
                success = o3d.io.write_point_cloud(
                    str(output_file),
                    pcd,
                    write_ascii=False,
                    compressed=False
                )
                
                if success:
                    reduction = (1 - len(pcd.points) / original_points) * 100 if original_points > 0 else 0
                    color_status = "âœ… RGB" if pcd.has_colors() else "âš ï¸ No RGB"
                    voxel_info = f" (voxel={voxel_size:.3f}m)" if voxel_size else ""
                    self.log_message(f"   ğŸ“¦ File {file_index}.pcd: {original_points:,} â†’ {len(pcd.points):,} points ({reduction:.1f}% reduction){voxel_info} {color_status}")
                    processed_count += 1
                else:
                    # Copy file gá»‘c náº¿u khÃ´ng lÆ°u Ä‘Æ°á»£c
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                    
            except Exception as e:
                # Copy file gá»‘c náº¿u cÃ³ lá»—i
                try:
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                except:
                    pass
                continue
        
        # Copy cÃ¡c file khÃ´ng quÃ¡ lá»›n tá»« map gá»‘c
        for file_index, _ in enumerate(poses):
            if file_index in [f[0] for f in large_files]:
                continue  # ÄÃ£ xá»­ lÃ½ rá»“i
            
            original_pcd_file = pcd_dir / f"{file_index}.pcd"
            if original_pcd_file.exists():
                try:
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                except:
                    pass
        
        if processed_count > 0:
            self.log_message(f"âœ… ÄÃ£ tá»± Ä‘á»™ng downsample {processed_count} file PCD quÃ¡ lá»›n")
            self.log_message(f"   Optimized map: {optimized_map_dir}")
            return str(optimized_map_dir)
        
        return None
    
    @staticmethod
    def _downsample_single_file(args):
        """
        Worker function Ä‘á»ƒ downsample má»™t file PCD (dÃ¹ng cho multiprocessing)
        Args: (pcd_file_path, output_path, dynamic_voxel_size, max_points_per_file, target_points_per_file, file_downsample_voxel_size)
        Returns: (success, file_index, original_points, downsampled_points, has_colors, error_msg)
        """
        try:
            pcd_file_path, output_path, dynamic_voxel_size, max_points_per_file, target_points_per_file, file_downsample_voxel_size = args
            
            if not HAS_OPEN3D:
                return (False, None, 0, 0, False, "open3d not available")
            
            import numpy as np
            
            # Äá»c PCD file
            pcd = o3d.io.read_point_cloud(str(pcd_file_path), format='auto')
            if len(pcd.points) == 0:
                return (False, None, 0, 0, False, "Empty point cloud")
            
            original_points = len(pcd.points)
            has_colors = pcd.has_colors()
            
            # Auto-downsample náº¿u file quÃ¡ lá»›n
            if original_points > max_points_per_file:
                if has_colors:
                    colors = np.asarray(pcd.colors)
                    if colors.max() > 1.0 and colors.max() <= 255.0:
                        pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
                
                # TÃ­nh voxel size Ä‘á»™ng
                reduction_ratio = original_points / target_points_per_file
                file_voxel_size = file_downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                file_voxel_size = max(0.05, min(0.5, file_voxel_size))
                
                pcd = pcd.voxel_down_sample(voxel_size=file_voxel_size)
            
            # Downsample thÃªm vá»›i voxel size cá»§a map
            if len(pcd.points) > 0:
                pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
            
            downsampled_points = len(pcd.points)
            
            # LÆ°u file
            success = o3d.io.write_point_cloud(
                str(output_path),
                pcd,
                write_ascii=False,
                compressed=False
            )
            
            if success:
                return (True, None, original_points, downsampled_points, pcd.has_colors(), None)
            else:
                return (False, None, original_points, 0, False, "Failed to write file")
                
        except Exception as e:
            return (False, None, 0, 0, False, str(e))
    
    def downsample_map_tiles(self, map_dir_path, total_map_points=None):
        """
        Downsample táº¥t cáº£ PCD tiles trong map directory (song song Ä‘á»ƒ nhanh hÆ¡n)
        Voxel size Ä‘Æ°á»£c tÃ­nh Ä‘á»™ng dá»±a trÃªn tá»•ng sá»‘ points Ä‘á»ƒ Ä‘áº£m báº£o giáº£m Ä‘á»§
        
        CÃ¡ch Ä‘á»c tiles PCD (tÃ­ch há»£p tá»« Recorder):
        - Äá»c pose.json Ä‘á»ƒ láº¥y file_index
        - Sá»­ dá»¥ng file_index Ä‘á»ƒ táº¡o path: pcd_dir / f"{file_index}.pcd"
        """
        if not HAS_OPEN3D:
            self.log_message("âŒ open3d khÃ´ng Ä‘Æ°á»£c cÃ i Ä‘áº·t. KhÃ´ng thá»ƒ downsample map.")
            self.log_message("ğŸ’¡ CÃ i Ä‘áº·t: pip3 install open3d")
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists() or not pcd_dir.exists():
            self.log_message("âŒ Map directory khÃ´ng há»£p lá»‡")
            return None
        
        # TÃ­nh toÃ¡n voxel size Ä‘á»™ng dá»±a trÃªn tá»•ng sá»‘ points
        # Map cÃ ng lá»›n â†’ voxel size cÃ ng lá»›n â†’ downsample cÃ ng nhiá»u
        if total_map_points:
            # Target: giáº£m xuá»‘ng ~2-3M points Ä‘á»ƒ RViz ráº¥t mÆ°á»£t (giáº£m tá»« 4M)
            target_points = 2_500_000  # 2.5M points target (giáº£m tá»« 4M)
            if total_map_points > target_points:
                reduction_ratio = total_map_points / target_points
                # Cube root vÃ¬ volume tá»· lá»‡ vá»›i size^3
                dynamic_voxel_size = self.downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                # Giá»›i háº¡n trong khoáº£ng há»£p lÃ½ (0.18m - 0.35m) - tÄƒng Ä‘á»ƒ downsample nhiá»u hÆ¡n
                dynamic_voxel_size = max(0.18, min(0.35, dynamic_voxel_size))
            else:
                dynamic_voxel_size = self.downsample_voxel_size
        else:
            dynamic_voxel_size = self.downsample_voxel_size
        
        # Táº¡o thÆ° má»¥c downsampled map
        temp_dir = Path(tempfile.gettempdir()) / "localization2_downsampled"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        downsampled_map_dir = temp_dir / f"{map_dir.name}_downsampled"
        downsampled_map_dir.mkdir(exist_ok=True)
        downsampled_pcd_dir = downsampled_map_dir / "pcd"
        downsampled_pcd_dir.mkdir(exist_ok=True)
        
        # Copy pose.json
        shutil.copy2(pose_file, downsampled_map_dir / "pose.json")
        
        # Äá»c pose.json
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            self.log_message(f"âŒ Lá»—i khi Ä‘á»c pose.json: {e}")
            return None
        
        self.log_message(f"ğŸ“‰ Äang downsample {len(poses)} PCD tiles (voxel_size={dynamic_voxel_size:.3f}m)...")
        
        # Chuáº©n bá»‹ danh sÃ¡ch files Ä‘á»ƒ xá»­ lÃ½ song song
        files_to_process = []
        for file_index, _ in enumerate(poses):
            pcd_file = pcd_dir / f"{file_index}.pcd"
            if pcd_file.exists():
                downsampled_pcd_file = downsampled_pcd_dir / f"{file_index}.pcd"
                files_to_process.append((
                    str(pcd_file),
                    str(downsampled_pcd_file),
                    dynamic_voxel_size,
                    self.max_points_per_file,
                    self.target_points_per_file,
                    self.file_downsample_voxel_size
                ))
        
        # Sá»­ dá»¥ng multiprocessing Ä‘á»ƒ xá»­ lÃ½ song song (nhanh hÆ¡n nhiá»u)
        loaded_count = 0
        failed_count = 0
        total_points_before = 0
        total_points_after = 0
        has_rgb_count = 0
        
        if HAS_MULTIPROCESSING and len(files_to_process) > 10:
            # Sá»­ dá»¥ng multiprocessing náº¿u cÃ³ nhiá»u files (>10)
            num_workers = min(cpu_count(), 8)  # Tá»‘i Ä‘a 8 workers Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
            self.log_message(f"   ğŸš€ Sá»­ dá»¥ng {num_workers} workers Ä‘á»ƒ downsample song song (nhanh hÆ¡n ~{num_workers}x)...")
            
            try:
                with Pool(processes=num_workers) as pool:
                    results = pool.map(self._downsample_single_file, files_to_process)
                
                # Xá»­ lÃ½ káº¿t quáº£
                for i, (success, _, orig_points, down_points, has_colors, error_msg) in enumerate(results):
                    if success:
                        loaded_count += 1
                        total_points_before += orig_points
                        total_points_after += down_points
                        if has_colors:
                            has_rgb_count += 1
                        
                        # Progress indicator
                        if loaded_count % 50 == 0 or loaded_count == len(files_to_process):
                            reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
                            self.log_message(f"  ğŸ“¦ ÄÃ£ downsample {loaded_count}/{len(files_to_process)} tiles, "
                                           f"{total_points_after:,} points ({reduction:.1f}% reduction)...")
                    else:
                        failed_count += 1
                        if failed_count <= 5 and error_msg:
                            self.log_message(f"  âš ï¸  Lá»—i: {error_msg}")
            except Exception as e:
                self.log_message(f"  âš ï¸  Lá»—i multiprocessing, chuyá»ƒn sang xá»­ lÃ½ tuáº§n tá»±: {e}")
                # Reset counters for sequential processing
                loaded_count = 0
                failed_count = 0
                total_points_before = 0
                total_points_after = 0
                has_rgb_count = 0
        
        # Xá»­ lÃ½ tuáº§n tá»± náº¿u khÃ´ng dÃ¹ng multiprocessing hoáº·c cÃ³ lá»—i
        # CÃ¡ch Ä‘á»c tiles tá»« Recorder: sá»­ dá»¥ng file_index Ä‘á»ƒ táº¡o path
        use_sequential = not (HAS_MULTIPROCESSING and len(files_to_process) > 10) or loaded_count == 0
        if use_sequential:
            for file_index, (tx, ty, tz, w, x, y, z) in enumerate(poses):
                # CÃ¡ch Ä‘á»c tiles tá»« Recorder: pcd_dir / f"{file_index}.pcd"
                pcd_file = pcd_dir / f"{file_index}.pcd"
                downsampled_pcd_file = downsampled_pcd_dir / f"{file_index}.pcd"
                
                if not pcd_file.exists():
                    failed_count += 1
                    continue
                
                try:
                    # Äá»c PCD file vá»›i auto-downsample náº¿u file quÃ¡ lá»›n
                    pcd, was_auto_downsampled, voxel_size = self._read_pcd_with_auto_downsample(pcd_file, preserve_colors=True)
                    
                    if pcd is None or len(pcd.points) == 0:
                        failed_count += 1
                        continue
                    
                    # Äáº¿m points gá»‘c
                    if was_auto_downsampled:
                        try:
                            original_pcd = o3d.io.read_point_cloud(str(pcd_file))
                            points_before_file = len(original_pcd.points) if original_pcd else len(pcd.points)
                        except:
                            points_before_file = int(len(pcd.points) * 1.5)
                    else:
                        points_before_file = len(pcd.points)
                    
                    total_points_before += points_before_file
                    has_colors = pcd.has_colors()
                    
                    # Downsample thÃªm vá»›i voxel size Ä‘á»™ng
                    downsampled_pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                    total_points_after += len(downsampled_pcd.points)
                    
                    # Äáº£m báº£o colors Ä‘Æ°á»£c preserve
                    if has_colors and not downsampled_pcd.has_colors():
                        import numpy as np
                        if HAS_SCIPY and cKDTree:
                            original_points = np.asarray(pcd.points)
                            original_colors = np.asarray(pcd.colors)
                            downsampled_points = np.asarray(downsampled_pcd.points)
                            tree = cKDTree(original_points)
                            _, indices = tree.query(downsampled_points, k=1)
                            downsampled_colors = original_colors[indices]
                            downsampled_pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                    
                    # LÆ°u file
                    success = o3d.io.write_point_cloud(
                        str(downsampled_pcd_file), 
                        downsampled_pcd, 
                        write_ascii=False,
                        compressed=False
                    )
                    if not success:
                        failed_count += 1
                        continue
                    
                    loaded_count += 1
                    if downsampled_pcd.has_colors():
                        has_rgb_count += 1
                    
                    # Progress indicator
                    if loaded_count % 50 == 0 or loaded_count == len(poses):
                        reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
                        self.log_message(f"  ğŸ“¦ ÄÃ£ downsample {loaded_count}/{len(poses)} tiles, "
                                       f"{total_points_after:,} points ({reduction:.1f}% reduction)...")
                        
                except Exception as e:
                    failed_count += 1
                    if failed_count <= 5:
                        self.log_message(f"  âš ï¸  Lá»—i khi downsample {pcd_file.name}: {e}")
                    continue
        
        if loaded_count == 0:
            self.log_message("âŒ KhÃ´ng downsample Ä‘Æ°á»£c tile nÃ o")
            return None
        
        if failed_count > 0:
            self.log_message(f"âš ï¸  {failed_count} tiles khÃ´ng downsample Ä‘Æ°á»£c")
        
        reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
        
        # Kiá»ƒm tra xem cÃ³ colors trong downsampled map khÃ´ng
        sample_pcd = o3d.io.read_point_cloud(str(downsampled_pcd_dir / "0.pcd"))
        has_rgb = sample_pcd.has_colors() if sample_pcd and len(sample_pcd.points) > 0 else False
        
        self.log_message(f"âœ… ÄÃ£ downsample {loaded_count} tiles")
        self.log_message(f"   Points: {total_points_before:,} â†’ {total_points_after:,} ({reduction:.1f}% reduction)")
        if has_rgb_count > 0:
            rgb_percent = (has_rgb_count / loaded_count) * 100 if loaded_count > 0 else 0
            self.log_message(f"   âœ… {has_rgb_count}/{loaded_count} files cÃ³ RGB colors ({rgb_percent:.1f}%) - map sáº½ hiá»ƒn thá»‹ Ä‘áº§y Ä‘á»§ mÃ u sáº¯c")
        else:
            self.log_message(f"   âš ï¸ No RGB colors detected - map sáº½ hiá»ƒn thá»‹ mÃ u vÃ ng máº·c Ä‘á»‹nh")
        self.log_message(f"   Downsampled map: {downsampled_map_dir}")
        
        return str(downsampled_map_dir)
    
    def _start_localization2_with_map(self, map_dir):
        """Start Localization2 vá»›i map directory Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½"""
        try:
            # Make script executable
            os.chmod(self.script_path, 0o755)
            
            # Start localization2
            cmd = [str(self.script_path), map_dir]
            self.log_message(f"Executing: {' '.join(cmd)}")
            
            self.localization_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                cwd=str(self.project_root)
            )
            
            # Start ROS listener
            self.start_ros_listener()
            
            # Read output vÃ  filter warnings khÃ´ng cáº§n thiáº¿t
            warnings_to_filter = [
                "Failed to find match for field 'normal_x'",
                "Failed to find match for field 'normal_y'",
                "Failed to find match for field 'normal_z'",
                "Failed to find match for field 'intensity'",
                "Failed to find match for field 'curvature'",
            ]
            
            warning_count = {}
            for warning in warnings_to_filter:
                warning_count[warning] = 0
            
            warning_shown = False  # Chá»‰ hiá»ƒn thá»‹ warning message má»™t láº§n
            
            for line in iter(self.localization_process.stdout.readline, ''):
                if not line:
                    break
                
                line_stripped = line.strip()
                
                # Filter warnings vá» missing fields (chá»‰ hiá»ƒn thá»‹ summary)
                should_filter = False
                matched_warning = None
                for warning in warnings_to_filter:
                    if warning in line_stripped:
                        warning_count[warning] += 1
                        should_filter = True
                        matched_warning = warning
                        break
                
                if not should_filter:
                    self.log_message(line_stripped)
                elif not warning_shown:
                    # Hiá»ƒn thá»‹ warning Ä‘áº§u tiÃªn vá»›i note
                    self.log_message(f"âš ï¸ PCD files missing some fields (normal_x, normal_y, intensity, etc.) - this is normal for PointXYZRGB format. Warnings will be suppressed.")
                    warning_shown = True
            
            # Hiá»ƒn thá»‹ summary náº¿u cÃ³ nhiá»u warnings
            total_warnings = sum(warning_count.values())
            if total_warnings > 10:
                self.log_message(f"â„¹ï¸ Suppressed {total_warnings} PCD field warnings (normal for PointXYZRGB format)")
            
            # Process finished
            return_code = self.localization_process.wait()
            self.localization_process = None
            
            if return_code == 0:
                self.log_message("âœ… Localization2 finished successfully")
            else:
                self.log_message(f"âš ï¸ Localization2 finished with return code: {return_code}")
            
        except Exception as e:
            self.log_message(f"âŒ Error starting Localization2: {e}")
        finally:
            self._reset_ui_state()
    
    def stop_localization2(self):
        """Stop Localization2"""
        self.log_message("Stopping Localization2...")
        
        # Stop ROS listener
        self.stop_ros_listener()
        
        # Stop process
        if self.localization_process:
            try:
                if platform.system() == "Windows":
                    self.localization_process.terminate()
                else:
                    os.kill(self.localization_process.pid, signal.SIGTERM)
                
                # Wait a bit
                time.sleep(2)
                
                # Force kill if still running
                if self.localization_process.poll() is None:
                    if platform.system() == "Windows":
                        self.localization_process.kill()
                    else:
                        os.kill(self.localization_process.pid, signal.SIGKILL)
                
                self.log_message("âœ… Localization2 stopped")
            except Exception as e:
                self.log_message(f"âš ï¸ Error stopping process: {e}")
        
        # Kill any remaining localization processes
        try:
            if platform.system() != "Windows":
                subprocess.run(['pkill', '-f', 'localization'], timeout=3, capture_output=True)
                subprocess.run(['pkill', '-f', 'fast_lio_localization'], timeout=3, capture_output=True)
        except:
            pass
        
        self._reset_ui_state()
    
    def _reset_ui_state(self):
        """Reset UI state"""
        self.is_localization_running = False
        self.start_button.config(state=tk.NORMAL)
        self.stop_button.config(state=tk.DISABLED)
        self.status_var.set("Stopped")
    
    def start_ros_listener(self):
        """Start ROS2 listener for localization data"""
        if not ROS2_AVAILABLE:
            self.log_message("âš ï¸ ROS2 not available, cannot subscribe to /Odometry")
            return
        
        if self.is_ros_running:
            return
        
        def ros_thread():
            try:
                if not rclpy.ok():
                    rclpy.init()
                
                self.ros_node = LocalizationListenerNode(self)
                self.ros_executor = MultiThreadedExecutor()
                self.ros_executor.add_node(self.ros_node)
                
                self.is_ros_running = True
                self.log_message("âœ… Started ROS2 listener for /Odometry topic")
                
                # Run executor
                self.ros_executor.spin()
            except Exception as e:
                self.log_message(f"âŒ Error in ROS2 listener: {e}")
            finally:
                self.is_ros_running = False
        
        self.ros_thread = threading.Thread(target=ros_thread, daemon=True)
        self.ros_thread.start()
    
    def stop_ros_listener(self):
        """Stop ROS2 listener"""
        if not self.is_ros_running:
            return
        
        try:
            if self.ros_executor:
                self.ros_executor.shutdown()
            if self.ros_node:
                self.ros_node.destroy_node()
            if rclpy.ok():
                rclpy.shutdown()
            self.log_message("âœ… Stopped ROS2 listener")
        except Exception as e:
            self.log_message(f"âš ï¸ Error stopping ROS2 listener: {e}")
        finally:
            self.is_ros_running = False
    
    def update_localization_data(self, msg):
        """Update localization data from ROS message"""
        try:
            # Extract data from message
            pos = msg.pose.pose.position
            orient = msg.pose.pose.orientation
            vel = msg.twist.twist.linear
            
            # Update UI (must be done in main thread)
            self.after(0, lambda: self._update_ui_data(
                pos.x, pos.y, pos.z,
                orient.x, orient.y, orient.z, orient.w,
                vel.x, vel.y, vel.z,
                msg.header.stamp
            ))
        except Exception as e:
            if ROS2_AVAILABLE and self.ros_node:
                self.ros_node.get_logger().error(f'Error updating localization data: {e}')
    
    def _update_ui_data(self, px, py, pz, ox, oy, oz, ow, vx, vy, vz, stamp):
        """Update UI with localization data (called from main thread)"""
        try:
            self.position_var.set(f"({px:.3f}, {py:.3f}, {pz:.3f})")
            self.orientation_var.set(f"({ox:.3f}, {oy:.3f}, {oz:.3f}, {ow:.3f})")
            self.velocity_var.set(f"({vx:.3f}, {vy:.3f}, {vz:.3f})")
            
            # Convert timestamp
            if hasattr(stamp, 'sec') and hasattr(stamp, 'nanosec'):
                dt = datetime.fromtimestamp(stamp.sec + stamp.nanosec / 1e9)
                self.timestamp_var.set(dt.strftime("%H:%M:%S.%f")[:-3])
            else:
                self.timestamp_var.set("N/A")
        except Exception as e:
            self.log_message(f"Error updating UI: {e}")

