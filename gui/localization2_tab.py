#!/usr/bin/env python3
"""
Localization2 Tab Module
Tab ƒë·ªÉ ƒëi·ªÅu khi·ªÉn Localization2 system v·ªõi FAST-LIVO2
"""

import threading
import subprocess
from pathlib import Path
from datetime import datetime
import os
import platform
import signal
import sys
import time
import tempfile
import queue
import re
import shutil
from functools import partial

# Multiprocessing for parallel downsampling
try:
    from multiprocessing import Pool, cpu_count
    HAS_MULTIPROCESSING = True
except ImportError:
    HAS_MULTIPROCESSING = False
    cpu_count = lambda: 1

# Open3D v√† scipy imports (optional, for map loading)
try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    HAS_OPEN3D = False

try:
    from scipy.spatial.transform import Rotation
    from scipy.spatial import cKDTree
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    cKDTree = None

# ROS2 imports with graceful fallback
try:
    import rclpy
    from rclpy.node import Node
    from rclpy.executors import MultiThreadedExecutor
    from nav_msgs.msg import Odometry
    ROS2_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  ROS2 not available. Localization2 tab will be limited.")
    ROS2_AVAILABLE = False
    # Create dummy classes for when ROS2 is not available
    class Node:
        def __init__(self, *args, **kwargs):
            pass
    class MultiThreadedExecutor:
        def __init__(self, *args, **kwargs):
            pass
    class Odometry:
        pass

try:
    import tkinter as tk
    from tkinter import ttk, messagebox, scrolledtext, filedialog
except ImportError as e:
    print(f"L·ªói import: {e}")
    import sys
    sys.exit(1)


class LocalizationListenerNode(Node):
    """ROS2 node to listen to localization odometry topic"""
    
    def __init__(self, localization_tab):
        if not ROS2_AVAILABLE:
            return
        super().__init__('localization_listener')
        self.localization_tab = localization_tab
        
        # Subscribe to /Odometry (default topic from localization2)
        try:
            self.subscription = self.create_subscription(
                Odometry,
                '/Odometry',
                self.localization_callback,
                10  # QoS depth
            )
            self.get_logger().info('‚úÖ Subscribed to /Odometry topic (localization2 default)')
        except Exception as e:
            self.get_logger().error(f'Failed to subscribe to /Odometry: {e}')
    
    def localization_callback(self, msg):
        """Callback for /Odometry topic messages"""
        try:
            # Pass the message to the Localization2Tab for processing
            self.localization_tab.update_localization_data(msg)
        except Exception as e:
            if ROS2_AVAILABLE:
                self.get_logger().error(f'Error in localization callback: {e}')


class Localization2Tab(ttk.Frame):
    """Tab cho Localization2 Control"""
    
    def __init__(self, parent):
        super().__init__(parent)
        
        # Paths
        self.project_root = Path(__file__).parent.parent
        self.workspace_path = self.project_root / "ws"
        self.script_path = self.project_root / "scripts" / "start_localization2.sh"
        self.log_dir = self.workspace_path / "src" / "FAST-LIVO2" / "Log"
        
        # Processes
        self.localization_process = None
        
        # ROS2
        self.ros_node = None
        self.ros_executor = None
        self.ros_thread = None
        self.is_ros_running = False
        
        # State
        self.is_localization_running = False
        self.selected_map_dir = None
        self.map_info_loaded = False  # Flag ƒë·ªÉ bi·∫øt ƒë√£ load map info ch∆∞a
        
        # Map size limits (ƒë·ªÉ tr√°nh crash RViz v√† ƒë·∫£m b·∫£o RViz m∆∞·ª£t)
        self.max_map_points = 50_000_000  # 50M points - gi·ªõi h·∫°n an to√†n
        self.warning_map_points = 5_000_000  # 5M points - t·ª± ƒë·ªông optimize (gi·∫£m t·ª´ 8M)
        self.safe_map_points = 2_000_000  # 2M points - lu√¥n optimize (gi·∫£m t·ª´ 3M)
        self.downsample_voxel_size = 0.22  # Voxel size cho downsample (m) - tƒÉng ƒë·ªÉ downsample nhi·ªÅu h∆°n (0.18 -> 0.22)
        
        # Per-file PCD limits (ƒë·ªÉ RViz m∆∞·ª£t h∆°n - gi·∫£m m·∫°nh ƒë·ªÉ downsample nhi·ªÅu h∆°n)
        self.max_points_per_file = 500_000  # 500K points per file - t·ª± ƒë·ªông downsample n·∫øu v∆∞·ª£t (gi·∫£m t·ª´ 800K)
        self.file_downsample_voxel_size = 0.15  # Voxel size c∆° b·∫£n cho auto-downsample file (m) - tƒÉng (0.12 -> 0.15)
        self.target_points_per_file = 300_000  # Target points sau downsample (~300K ƒë·ªÉ RViz r·∫•t m∆∞·ª£t, gi·∫£m t·ª´ 500K)
        
        # Localization data
        self.position_var = None
        self.orientation_var = None
        self.velocity_var = None
        self.timestamp_var = None
        
        # T·∫°o UI
        self.create_widgets()
    
    def create_widgets(self):
        """T·∫°o c√°c widget cho tab Localization2"""
        
        # Main container v·ªõi scrollbar
        main_container = ttk.Frame(self)
        main_container.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Canvas v√† scrollbar
        self.canvas = tk.Canvas(main_container, highlightthickness=0)
        scrollbar = ttk.Scrollbar(main_container, orient="vertical", command=self.canvas.yview)
        self.scrollable_frame = ttk.Frame(self.canvas)
        
        # Configure scrollable frame
        def configure_scroll_region(event=None):
            self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        
        self.scrollable_frame.bind("<Configure>", configure_scroll_region)
        
        # Create window in canvas
        self.canvas_window = self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        
        # Configure canvas scrolling - ensure width matches canvas
        def configure_canvas_width(event):
            canvas_width = event.width
            self.canvas.itemconfig(self.canvas_window, width=canvas_width)
            # Update scroll region after width change
            self.after_idle(lambda: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        
        self.canvas.bind('<Configure>', configure_canvas_width)
        self.canvas.configure(yscrollcommand=scrollbar.set)
        
        # Mouse wheel scrolling
        def on_mousewheel(event):
            self.canvas.yview_scroll(int(-1 * (event.delta / 120)), "units")
        
        self.canvas.bind_all("<MouseWheel>", on_mousewheel)
        
        # Pack canvas and scrollbar
        self.canvas.pack(side="left", fill="both", expand=True)
        scrollbar.pack(side="right", fill="y")
        
        # Configure main container
        main_container.columnconfigure(0, weight=1)
        main_container.rowconfigure(0, weight=1)
        
        # Store canvas reference for later updates
        self.main_canvas = self.canvas
        
        # Map Selection Section
        self.setup_map_selection()
        
        # Control Section
        self.setup_control()
        
        # Localization Data Section
        self.setup_localization_data()
        
        # Status and Log Section
        self.setup_status_log()
        
        # Configure grid weights
        self.scrollable_frame.columnconfigure(0, weight=1)
        
        # Update canvas scroll region after all widgets are created
        self.after(100, lambda: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
    
    def setup_map_selection(self):
        """Setup map selection section"""
        map_frame = ttk.LabelFrame(self.scrollable_frame, text="Map Selection", padding="10")
        map_frame.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(map_frame, text="Select a map directory from FAST-LIVO2 Log", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Selected map display
        self.map_dir_var = tk.StringVar(value="No map selected")
        self.map_dir_label = ttk.Label(map_frame, text="Selected map:", font=('Arial', 10))
        self.map_dir_label.grid(row=1, column=0, sticky=tk.W, pady=(0, 5))
        
        self.map_dir_display = ttk.Label(map_frame, textvariable=self.map_dir_var, 
                                         font=('Arial', 9), foreground='blue', wraplength=600)
        self.map_dir_display.grid(row=2, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Buttons
        buttons_frame = ttk.Frame(map_frame)
        buttons_frame.grid(row=3, column=0, columnspan=2, pady=(0, 5))
        
        self.select_map_button = ttk.Button(buttons_frame, text="üìÅ Select Map Directory", 
                                           command=self.select_map_directory)
        self.select_map_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.select_latest_button = ttk.Button(buttons_frame, text="‚¨áÔ∏è Select Latest Map", 
                                               command=self.select_latest_map)
        self.select_latest_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.load_map_info_button = ttk.Button(buttons_frame, text="üìä Load Map Info", 
                                               command=self.load_map_info)
        self.load_map_info_button.pack(side=tk.LEFT)
        
        # Map info display
        self.map_info_var = tk.StringVar(value="No map info loaded - Click 'Load Map Info' to analyze")
        self.map_info_label = ttk.Label(map_frame, textvariable=self.map_info_var, 
                                       font=('Arial', 9), foreground='green', wraplength=600, justify=tk.LEFT)
        self.map_info_label.grid(row=4, column=0, columnspan=2, sticky=tk.W, pady=(10, 5))
        
        # Configure grid weights
        map_frame.columnconfigure(0, weight=1)
    
    def setup_control(self):
        """Setup control section"""
        control_frame = ttk.LabelFrame(self.scrollable_frame, text="Localization2 Control", padding="10")
        control_frame.grid(row=1, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(control_frame, text="FAST_LIO_LOCALIZATION2 system for localization", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Status
        self.status_var = tk.StringVar(value="Stopped")
        self.status_label = ttk.Label(control_frame, textvariable=self.status_var, 
                                      font=('Arial', 10, 'bold'))
        self.status_label.grid(row=1, column=0, columnspan=2, pady=(0, 10))
        
        # Control buttons
        buttons_frame = ttk.Frame(control_frame)
        buttons_frame.grid(row=2, column=0, columnspan=2, pady=(0, 5))
        
        self.start_button = ttk.Button(buttons_frame, text="üöÄ Start Localization2", 
                                      command=self.start_localization2)
        self.start_button.pack(side=tk.LEFT, padx=(0, 5))
        
        self.stop_button = ttk.Button(buttons_frame, text="‚èπÔ∏è Stop Localization2", 
                                     command=self.stop_localization2, state=tk.DISABLED)
        self.stop_button.pack(side=tk.LEFT)
        
        # Configure grid weights
        control_frame.columnconfigure(0, weight=1)
    
    def setup_localization_data(self):
        """Setup localization data display section"""
        data_frame = ttk.LabelFrame(self.scrollable_frame, text="Localization Data (/Odometry)", padding="10")
        data_frame.grid(row=2, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Description
        desc_label = ttk.Label(data_frame, text="Real-time pose data from /Odometry topic", 
                              font=('Arial', 9), foreground='gray')
        desc_label.grid(row=0, column=0, columnspan=2, sticky=tk.W, pady=(0, 10))
        
        # Current pose display
        current_frame = ttk.Frame(data_frame)
        current_frame.grid(row=1, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 5))
        
        # Position
        ttk.Label(current_frame, text="Position (x, y, z):", font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky=tk.W, padx=(0, 10))
        self.position_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.position_var, font=('Courier', 9), foreground='blue').grid(row=0, column=1, sticky=tk.W)
        
        # Orientation
        ttk.Label(current_frame, text="Orientation (x, y, z, w):", font=('Arial', 10, 'bold')).grid(row=1, column=0, sticky=tk.W, padx=(0, 10))
        self.orientation_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.orientation_var, font=('Courier', 9), foreground='blue').grid(row=1, column=1, sticky=tk.W)
        
        # Velocity
        ttk.Label(current_frame, text="Velocity (x, y, z):", font=('Arial', 10, 'bold')).grid(row=2, column=0, sticky=tk.W, padx=(0, 10))
        self.velocity_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.velocity_var, font=('Courier', 9), foreground='blue').grid(row=2, column=1, sticky=tk.W)
        
        # Timestamp
        ttk.Label(current_frame, text="Last Update:", font=('Arial', 10, 'bold')).grid(row=3, column=0, sticky=tk.W, padx=(0, 10))
        self.timestamp_var = tk.StringVar(value="N/A")
        ttk.Label(current_frame, textvariable=self.timestamp_var, font=('Courier', 9), foreground='green').grid(row=3, column=1, sticky=tk.W)
        
        # Configure grid weights
        data_frame.columnconfigure(0, weight=1)
        current_frame.columnconfigure(1, weight=1)
    
    def setup_status_log(self):
        """Setup status and log section"""
        log_frame = ttk.LabelFrame(self.scrollable_frame, text="Status & Log", padding="10")
        log_frame.grid(row=3, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        # Create text widget with scrollbar
        self.log_text = tk.Text(log_frame, height=15, wrap=tk.WORD, font=('Courier', 9))
        log_scrollbar = ttk.Scrollbar(log_frame, orient="vertical", command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=log_scrollbar.set)
        
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        log_scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        # Clear log button
        self.clear_log_button = ttk.Button(log_frame, text="üóëÔ∏è Clear Log", 
                                          command=self.clear_log)
        self.clear_log_button.grid(row=1, column=0, sticky=tk.W, pady=(5, 0))
        
        # Configure grid weights
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
        
        # Update canvas scroll region after adding log frame
        self.after_idle(lambda: self.main_canvas.configure(scrollregion=self.main_canvas.bbox("all")))
    
    def find_latest_map_directory(self):
        """T√¨m map directory m·ªõi nh·∫•t trong Log/ c√≥ d·ªØ li·ªáu"""
        if not self.log_dir.exists():
            return None
        
        map_dirs = sorted(self.log_dir.glob("map_*"), key=lambda x: x.name, reverse=True)
        
        # T√¨m map ƒë·∫ßu ti√™n c√≥ d·ªØ li·ªáu (c√≥ PCD files ho·∫∑c pose.json c√≥ n·ªôi dung)
        for map_dir in map_dirs:
            if self.is_map_valid(map_dir):
                return map_dir
        
        return None
    
    def _check_pcd_format(self, pcd_file_path):
        """
        Ki·ªÉm tra format c·ªßa PCD file (c√≥ RGB hay kh√¥ng)
        Returns: True n·∫øu c√≥ RGB, False n·∫øu kh√¥ng
        """
        try:
            # ƒê·ªçc header c·ªßa PCD file ƒë·ªÉ ki·ªÉm tra format
            with open(pcd_file_path, 'rb') as f:
                header = f.read(2048).decode('utf-8', errors='ignore')
                # Ki·ªÉm tra xem c√≥ FIELDS ch·ª©a rgb ho·∫∑c rgba kh√¥ng
                if 'FIELDS' in header:
                    fields_line = [line for line in header.split('\n') if 'FIELDS' in line]
                    if fields_line:
                        fields = fields_line[0].upper()
                        # Ki·ªÉm tra c√≥ rgb ho·∫∑c rgba trong FIELDS
                        if 'RGB' in fields or 'RGBA' in fields:
                            return True
        except:
            pass
        return False
    
    def _read_pcd_with_auto_downsample(self, pcd_file_path, preserve_colors=True):
        """
        ƒê·ªçc PCD file v·ªõi t·ª± ƒë·ªông downsample n·∫øu qu√° l·ªõn
        ƒê·∫£m b·∫£o ƒë·ªçc ƒë√∫ng d·ªØ li·ªáu ƒë√£ qu√©t (colors, normals n·∫øu c√≥)
        Voxel size ƒë∆∞·ª£c t√≠nh ƒë·ªông: c√†ng nhi·ªÅu points ‚Üí downsample c√†ng nhi·ªÅu
        
        Args:
            pcd_file_path: Path ƒë·∫øn PCD file
            preserve_colors: C√≥ gi·ªØ colors kh√¥ng (default: True)
            
        Returns:
            tuple: (point_cloud, was_downsampled, voxel_size_used)
                - point_cloud: Point cloud ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (downsample n·∫øu c·∫ßn)
                - was_downsampled: True n·∫øu ƒë√£ downsample, False n·∫øu kh√¥ng
                - voxel_size_used: Voxel size ƒë√£ s·ª≠ d·ª•ng (None n·∫øu kh√¥ng downsample)
        """
        if not HAS_OPEN3D:
            return None, False
        
        try:
            # Ki·ªÉm tra format PCD file tr∆∞·ªõc khi ƒë·ªçc
            has_rgb_in_file = self._check_pcd_format(pcd_file_path)
            
            # ƒê·ªçc PCD file (open3d t·ª± ƒë·ªông detect format v√† preserve colors/normals)
            # Kh√¥ng c·∫ßn ch·ªâ ƒë·ªãnh format='auto' v√¨ ƒë√≥ l√† default
            pcd = o3d.io.read_point_cloud(str(pcd_file_path))
            
            if len(pcd.points) == 0:
                return None, False, None
            
            num_points = len(pcd.points)
            was_downsampled = False
            voxel_size_used = None
            
            # Ki·ªÉm tra xem colors c√≥ ƒë∆∞·ª£c ƒë·ªçc ƒë√∫ng kh√¥ng
            has_colors_after_read = pcd.has_colors()
            if has_rgb_in_file and not has_colors_after_read:
                # File c√≥ RGB nh∆∞ng kh√¥ng ƒë·ªçc ƒë∆∞·ª£c - c√≥ th·ªÉ l√† format issue
                # Th·ª≠ ƒë·ªçc l·∫°i v·ªõi format c·ª• th·ªÉ
                try:
                    # Th·ª≠ ƒë·ªçc v·ªõi format PCD (kh√¥ng ch·ªâ ƒë·ªãnh format c·ª• th·ªÉ)
                    pcd = o3d.io.read_point_cloud(str(pcd_file_path))
                    has_colors_after_read = pcd.has_colors()
                except:
                    pass
            
            # Ki·ªÉm tra n·∫øu file qu√° l·ªõn, t·ª± ƒë·ªông downsample
            if num_points > self.max_points_per_file:
                import numpy as np
                
                # Ki·ªÉm tra v√† preserve colors
                has_colors = pcd.has_colors()
                has_normals = pcd.has_normals()
                
                # L∆∞u colors g·ªëc tr∆∞·ªõc khi x·ª≠ l√Ω (ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng m·∫•t d·ªØ li·ªáu)
                original_colors = None
                if has_colors:
                    original_colors = np.asarray(pcd.colors).copy()
                    # Open3D l∆∞u colors trong range 0-1, nh∆∞ng PCD file c√≥ th·ªÉ l√† 0-255
                    # Ki·ªÉm tra xem colors c√≥ trong range n√†o
                    colors = np.asarray(pcd.colors)
                    # N·∫øu colors > 1.0, c√≥ th·ªÉ l√† ƒë√£ ƒë∆∞·ª£c normalize sai ho·∫∑c format kh√°c
                    # Ch·ªâ normalize n·∫øu th·ª±c s·ª± c·∫ßn (colors > 1.0 v√† c√≥ v·∫ª nh∆∞ l√† 0-255)
                    if colors.max() > 1.0 and colors.max() <= 255.0:
                        # Normalize t·ª´ 0-255 v·ªÅ 0-1 (open3d format)
                        pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
                    # N·∫øu colors ƒë√£ trong range 0-1, gi·ªØ nguy√™n
                
                # T√≠nh to√°n voxel size ƒë·ªông d·ª±a tr√™n s·ªë points
                # C√†ng nhi·ªÅu points th√¨ downsample c√†ng nhi·ªÅu (voxel size l·ªõn h∆°n)
                # Voxel downsample gi·∫£m points theo volume (t·ª∑ l·ªá v·ªõi voxel_size^3)
                # C√¥ng th·ª©c: voxel_size = base_size * (num_points / target_points)^(1/3)
                reduction_ratio = num_points / self.target_points_per_file
                # Cube root ƒë·ªÉ t√≠nh voxel size (v√¨ volume t·ª∑ l·ªá v·ªõi size^3)
                dynamic_voxel_size = self.file_downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                
                # Gi·ªõi h·∫°n voxel size trong kho·∫£ng h·ª£p l√Ω (0.05m - 0.5m)
                dynamic_voxel_size = max(0.05, min(0.5, dynamic_voxel_size))
                voxel_size_used = dynamic_voxel_size
                
                # Downsample v·ªõi voxel size ƒë·ªông (c√†ng nhi·ªÅu points ‚Üí voxel size c√†ng l·ªõn ‚Üí downsample c√†ng nhi·ªÅu)
                if preserve_colors:
                    # Voxel downsample t·ª± ƒë·ªông preserve colors
                    pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                else:
                    pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                
                # ƒê·∫£m b·∫£o colors ƒë∆∞·ª£c preserve sau downsample
                if has_colors and not pcd.has_colors():
                    # N·∫øu m·∫•t colors sau downsample (hi·∫øm khi x·∫£y ra v·ªõi open3d)
                    # Kh√¥i ph·ª•c t·ª´ original_colors ƒë√£ l∆∞u
                    if HAS_SCIPY and cKDTree and original_colors is not None:
                        # ƒê·ªçc l·∫°i file g·ªëc ƒë·ªÉ l·∫•y points g·ªëc
                        original_pcd = o3d.io.read_point_cloud(str(pcd_file_path), format='auto')
                        original_points = np.asarray(original_pcd.points)
                        downsampled_points = np.asarray(pcd.points)
                        
                        # T√¨m colors g·∫ßn nh·∫•t t·ª´ original
                        tree = cKDTree(original_points)
                        _, indices = tree.query(downsampled_points, k=1)
                        downsampled_colors = original_colors[indices]
                        pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                    elif original_colors is not None:
                        # Fallback: s·ª≠ d·ª•ng colors trung b√¨nh n·∫øu kh√¥ng c√≥ scipy
                        # (kh√¥ng l√Ω t∆∞·ªüng nh∆∞ng t·ªët h∆°n kh√¥ng c√≥ colors)
                        import numpy as np
                        avg_color = np.mean(original_colors, axis=0)
                        downsampled_colors = np.tile(avg_color, (len(pcd.points), 1))
                        pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                
                was_downsampled = True
                
            return pcd, was_downsampled, voxel_size_used
            
        except Exception as e:
            import traceback
            # Log l·ªói chi ti·∫øt ƒë·ªÉ debug
            print(f"Error reading PCD file {pcd_file_path}: {e}")
            print(traceback.format_exc())
            return None, False, None
    
    def is_map_valid(self, map_dir):
        """Ki·ªÉm tra map directory c√≥ d·ªØ li·ªáu h·ª£p l·ªá kh√¥ng (gi·ªëng pcd_viewer_tab.py)"""
        if not map_dir.exists():
            return False
        
        # Ki·ªÉm tra c√≥ pose.json
        pose_file = map_dir / "pose.json"
        if not pose_file.exists():
            return False
        
        # Ki·ªÉm tra pose.json c√≥ n·ªôi dung (kh√¥ng r·ªóng)
        try:
            if pose_file.stat().st_size == 0:
                return False
            
            # ƒê·ªçc v√† validate pose.json c√≥ √≠t nh·∫•t 1 pose h·ª£p l·ªá (gi·ªëng pcd_viewer_tab.py)
            poses_found = 0
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    # Format: tx ty tz w x y z (7 values)
                    if len(parts) >= 7:
                        try:
                            # Validate c√≥ th·ªÉ parse ƒë∆∞·ª£c
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses_found += 1
                            # Ch·ªâ c·∫ßn 1 pose h·ª£p l·ªá l√† ƒë·ªß
                            if poses_found >= 1:
                                break
                        except ValueError:
                            continue
            
            if poses_found == 0:
                return False
                
        except Exception:
            return False
        
        # Ki·ªÉm tra c√≥ pcd directory v√† c√≥ √≠t nh·∫•t 1 PCD file
        pcd_dir = map_dir / "pcd"
        if pcd_dir.exists():
            pcd_files = list(pcd_dir.glob("*.pcd"))
            if len(pcd_files) > 0:
                return True
        
        # N·∫øu kh√¥ng c√≥ PCD files nh∆∞ng pose.json c√≥ n·ªôi dung h·ª£p l·ªá, v·∫´n coi l√† valid
        # (c√≥ th·ªÉ l√† single file map ho·∫∑c map ƒëang ƒë∆∞·ª£c t·∫°o)
        return True
    
    def select_latest_map(self):
        """Ch·ªçn map m·ªõi nh·∫•t c√≥ d·ªØ li·ªáu"""
        latest_map = self.find_latest_map_directory()
        if latest_map:
            self.selected_map_dir = str(latest_map)
            self.map_dir_var.set(self.selected_map_dir)
            
            # ƒê·ªçc v√† hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ map (gi·ªëng pcd_viewer_tab.py)
            try:
                pose_file = latest_map / "pose.json"
                poses_count = 0
                if pose_file.exists():
                    with open(pose_file, 'r') as f:
                        for line in f:
                            line = line.strip()
                            if not line:
                                continue
                            parts = line.split()
                            if len(parts) >= 7:
                                try:
                                    float(parts[0]), float(parts[1]), float(parts[2])
                                    float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                                    poses_count += 1
                                except ValueError:
                                    continue
                
                pcd_count = len(list((latest_map / "pcd").glob("*.pcd"))) if (latest_map / "pcd").exists() else 0
                self.log_message(f"‚úÖ Selected latest valid map: {latest_map.name}")
                self.log_message(f"   üìÑ {poses_count} poses in pose.json")
                if pcd_count > 0:
                    self.log_message(f"   üì¶ {pcd_count} PCD tiles found")
                else:
                    self.log_message(f"   ‚ö†Ô∏è No PCD tiles found (using pose.json only)")
                
                # Reset map info khi ch·ªçn map m·ªõi
                self.map_info_loaded = False
                self.map_info_var.set(f"Map: {latest_map.name} | {poses_count} poses | {pcd_count} tiles - Click 'Load Map Info' for details")
            except Exception as e:
                self.log_message(f"‚úÖ Selected latest valid map: {latest_map.name}")
                self.log_message(f"   ‚ö†Ô∏è Could not read map details: {e}")
                self.map_info_loaded = False
                self.map_info_var.set("No map info loaded - Click 'Load Map Info' to analyze")
        else:
            messagebox.showwarning("Warning", "No valid map directories found in Log/\n(Maps must have pose.json with content)")
            self.log_message("‚ö†Ô∏è No valid map directories found")
    
    def select_map_directory(self):
        """Ch·ªçn map directory"""
        initial_dir = str(self.log_dir) if self.log_dir.exists() else str(self.project_root)
        selected = filedialog.askdirectory(
            title="Select Map Directory",
            initialdir=initial_dir
        )
        
        if selected:
            # Check if it's a valid map directory
            map_path = Path(selected)
            if (map_path / "pose.json").exists() or (map_path / "pcd").exists():
                self.selected_map_dir = selected
                self.map_dir_var.set(self.selected_map_dir)
                self.log_message(f"‚úÖ Selected map: {map_path.name}")
                # Reset map info khi ch·ªçn map m·ªõi
                self.map_info_loaded = False
                self.map_info_var.set("No map info loaded - Click 'Load Map Info' to analyze")
            else:
                messagebox.showwarning("Warning", "Selected directory doesn't appear to be a valid map directory.\nLooking for pose.json or pcd/ subdirectory.")
                self.log_message("‚ö†Ô∏è Invalid map directory selected")
    
    def log_message(self, message):
        """Th√™m message v√†o log"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.log_text.see(tk.END)
    
    def load_map_info(self):
        """Load v√† hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ map (gi·ªëng pcd_viewer_tab.py)"""
        if not self.selected_map_dir:
            messagebox.showwarning("Warning", "Please select a map directory first!")
            return
        
        map_path = Path(self.selected_map_dir)
        if not map_path.exists():
            messagebox.showerror("Error", "Selected map directory does not exist!")
            return
        
        # Load map info trong thread ri√™ng ƒë·ªÉ kh√¥ng block UI
        threading.Thread(target=self._load_map_info_worker, args=(str(map_path),), daemon=True).start()
    
    def _load_map_info_worker(self, map_dir_path):
        """Worker thread ƒë·ªÉ load map info"""
        try:
            map_info = self.load_map_tiles_info(map_dir_path)
            if map_info:
                # Update UI trong main thread
                def update_ui():
                    self.map_info_var.set(
                        f"Map: {map_info['name']}\n"
                        f"Tiles: {map_info['loaded_count']}/{map_info['total_poses']}\n"
                        f"Total Points: {map_info['total_points']:,}\n"
                        f"Failed: {map_info['failed_count']}"
                    )
                    self.map_info_loaded = True
                self.after(0, update_ui)
        except Exception as e:
            self.log_message(f"‚ùå Error loading map info: {e}")
            def update_error():
                self.map_info_var.set(f"Error loading map info: {e}")
            self.after(0, update_error)
    
    def load_map_tiles_info(self, map_dir_path):
        """Load v√† t√≠nh to√°n th√¥ng tin v·ªÅ map tiles (gi·ªëng pcd_viewer_tab.py nh∆∞ng kh√¥ng merge)"""
        if not HAS_OPEN3D:
            self.log_message("‚ö†Ô∏è open3d kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. Kh√¥ng th·ªÉ load map info chi ti·∫øt.")
            self.log_message("üí° C√†i ƒë·∫∑t: pip3 install open3d")
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists():
            self.log_message(f"‚ùå Kh√¥ng t√¨m th·∫•y pose.json t·∫°i: {pose_file}")
            return None
        
        if not pcd_dir.exists():
            self.log_message(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c pcd/ t·∫°i: {pcd_dir}")
            return None
        
        self.log_message(f"üìÇ ƒêang load map info t·ª´: {map_dir.name}")
        self.log_message(f"üìÑ ƒê·ªçc pose.json...")
        
        # ƒê·ªçc pose.json
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            self.log_message(f"‚ùå L·ªói khi ƒë·ªçc pose.json: {e}")
            return None
        
        if not poses:
            self.log_message("‚ùå Kh√¥ng c√≥ pose n√†o trong pose.json")
            return None
        
        self.log_message(f"üìä T√¨m th·∫•y {len(poses)} poses")
        self.log_message(f"üì¶ ƒêang ƒë·ªçc th√¥ng tin t·ª´ {len(poses)} PCD files...")
        
        # ƒê·ªçc th√¥ng tin t·ª´ c√°c PCD files (kh√¥ng merge, ch·ªâ ƒë·∫øm points)
        total_points = 0
        loaded_count = 0
        failed_count = 0
        downsampled_count = 0
        
        for file_index, (tx, ty, tz, w, x, y, z) in enumerate(poses):
            pcd_file = pcd_dir / f"{file_index}.pcd"
            
            if not pcd_file.exists():
                failed_count += 1
                continue
            
            try:
                # ƒê·ªçc PCD file v·ªõi auto-downsample n·∫øu c·∫ßn
                pcd, was_downsampled, voxel_size = self._read_pcd_with_auto_downsample(pcd_file, preserve_colors=True)
                
                if pcd is None or len(pcd.points) == 0:
                    failed_count += 1
                    continue
                
                num_points = len(pcd.points)
                total_points += num_points
                loaded_count += 1
                
                if was_downsampled:
                    downsampled_count += 1
                
                # Progress indicator
                if loaded_count % 50 == 0 or loaded_count == len(poses):
                    status = f" (auto-downsampled: {downsampled_count})" if downsampled_count > 0 else ""
                    self.log_message(f"  üì¶ ƒê√£ ƒë·ªçc {loaded_count}/{len(poses)} tiles, {total_points:,} points{status}...")
                    
            except Exception as e:
                failed_count += 1
                if failed_count <= 5:  # Ch·ªâ log 5 l·ªói ƒë·∫ßu ti√™n
                    self.log_message(f"  ‚ö†Ô∏è  L·ªói khi ƒë·ªçc {pcd_file.name}: {e}")
                continue
        
        if loaded_count == 0:
            self.log_message("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c tile n√†o")
            return None
        
        if failed_count > 0:
            self.log_message(f"‚ö†Ô∏è  {failed_count} tiles kh√¥ng ƒë·ªçc ƒë∆∞·ª£c")
        
        if downsampled_count > 0:
            self.log_message(f"‚úÖ ƒê√£ ƒë·ªçc {loaded_count} tiles, t·ªïng {total_points:,} points")
            self.log_message(f"   üìâ {downsampled_count} files ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông downsample (> {self.max_points_per_file:,} points/file)")
        else:
            self.log_message(f"‚úÖ ƒê√£ ƒë·ªçc {loaded_count} tiles, t·ªïng {total_points:,} points")
        
        return {
            'name': map_dir.name,
            'total_poses': len(poses),
            'loaded_count': loaded_count,
            'failed_count': failed_count,
            'total_points': total_points,
            'downsampled_count': downsampled_count
        }
    
    def clear_log(self):
        """X√≥a log"""
        self.log_text.delete(1.0, tk.END)
    
    def start_localization2(self):
        """Start Localization2"""
        if not self.selected_map_dir:
            messagebox.showerror("Error", "Please select a map directory first!")
            return
        
        if not os.path.exists(self.selected_map_dir):
            messagebox.showerror("Error", "Selected map directory does not exist!")
            return
        
        # Validate map directory
        map_path = Path(self.selected_map_dir)
        if not self.is_map_valid(map_path):
            messagebox.showerror("Error", 
                f"Selected map directory is invalid or empty!\n\n"
                f"Map must have:\n"
                f"  - pose.json file with content\n"
                f"  - pcd/ directory with .pcd files (optional but recommended)\n\n"
                f"Please select a valid map directory.")
            self.log_message(f"‚ùå Invalid map directory: {map_path.name}")
            self.log_message("   Map must have pose.json with content and optionally PCD files")
            return
        
        # Check if script exists
        if not self.script_path.exists():
            messagebox.showerror("Error", f"Start script not found: {self.script_path}")
            self.log_message(f"‚ùå Script not found: {self.script_path}")
            return
        
        self.log_message("Starting Localization2...")
        self.log_message(f"Map directory: {self.selected_map_dir}")
        
        # Update UI
        self.start_button.config(state=tk.DISABLED)
        self.stop_button.config(state=tk.NORMAL)
        self.status_var.set("Starting...")
        self.is_localization_running = True
        
        # Check map size v√† downsample n·∫øu c·∫ßn (trong thread ri√™ng ƒë·ªÉ kh√¥ng block UI)
        def start_thread():
            # Ki·ªÉm tra v√† downsample map n·∫øu c·∫ßn
            map_dir_to_use = self._check_and_downsample_map_if_needed()
            if not map_dir_to_use:
                self.log_message("‚ùå Failed to prepare map for localization")
                self._reset_ui_state()
                return
            
            # Start localization v·ªõi map ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
            self._start_localization2_with_map(map_dir_to_use)
        
        threading.Thread(target=start_thread, daemon=True).start()
    
    def _check_and_downsample_map_if_needed(self):
        """Ki·ªÉm tra k√≠ch th∆∞·ªõc map v√† downsample n·∫øu c·∫ßn"""
        map_path = Path(self.selected_map_dir)
        
        # Ki·ªÉm tra map info ƒë√£ ƒë∆∞·ª£c load ch∆∞a
        if not self.map_info_loaded:
            self.log_message("üìä ƒêang ki·ªÉm tra k√≠ch th∆∞·ªõc map...")
            map_info = self.load_map_tiles_info(str(map_path))
            if not map_info:
                self.log_message("‚ö†Ô∏è Kh√¥ng th·ªÉ ƒë·ªçc map info, ti·∫øp t·ª•c v·ªõi map g·ªëc")
                return str(map_path)
            
            total_points = map_info['total_points']
        else:
            # L·∫•y th√¥ng tin t·ª´ map_info_var n·∫øu ƒë√£ load
            # Parse t·ª´ map_info_var ƒë·ªÉ l·∫•y total_points
            map_info_text = self.map_info_var.get()
            try:
                # T√¨m "Total Points: X,XXX,XXX" trong text
                match = re.search(r'Total Points: ([\d,]+)', map_info_text)
                if match:
                    total_points = int(match.group(1).replace(',', ''))
                else:
                    # N·∫øu kh√¥ng parse ƒë∆∞·ª£c, load l·∫°i
                    map_info = self.load_map_tiles_info(str(map_path))
                    if not map_info:
                        return str(map_path)
                    total_points = map_info['total_points']
            except:
                # N·∫øu parse l·ªói, load l·∫°i
                map_info = self.load_map_tiles_info(str(map_path))
                if not map_info:
                    return str(map_path)
                total_points = map_info['total_points']
        
        self.log_message(f"üìä Map c√≥ {total_points:,} points")
        
        # Ki·ªÉm tra n·∫øu map qu√° n·∫∑ng
        if total_points > self.max_map_points:
            self.log_message(f"‚ö†Ô∏è Map qu√° n·∫∑ng ({total_points:,} points > {self.max_map_points:,})")
            self.log_message("üìâ T·ª± ƒë·ªông downsample map ƒë·ªÉ tr√°nh crash RViz...")
            
            downsampled_map_dir = self.downsample_map_tiles(str(map_path), total_map_points=total_points)
            if downsampled_map_dir:
                self.log_message(f"‚úÖ ƒê√£ downsample map th√†nh c√¥ng")
                return downsampled_map_dir
            else:
                self.log_message("‚ö†Ô∏è Kh√¥ng th·ªÉ downsample map, ti·∫øp t·ª•c v·ªõi map g·ªëc (c√≥ th·ªÉ crash RViz)")
                return str(map_path)
        elif total_points > self.warning_map_points:
            # Map > 5M points - t·ª± ƒë·ªông optimize ƒë·ªÉ tr√°nh lag RViz
            self.log_message(f"‚ö†Ô∏è Map kh√° n·∫∑ng ({total_points:,} points > {self.warning_map_points:,})")
            self.log_message("üìâ T·ª± ƒë·ªông downsample to√†n b·ªô map ƒë·ªÉ RViz m∆∞·ª£t h∆°n...")
            
            # T·ª± ƒë·ªông downsample map v·ªõi voxel size ƒë·ªông (kh√¥ng h·ªèi user ƒë·ªÉ tr√°nh gi√°n ƒëo·∫°n)
            downsampled_map_dir = self.downsample_map_tiles(str(map_path), total_map_points=total_points)
            if downsampled_map_dir:
                self.log_message(f"‚úÖ ƒê√£ downsample map th√†nh c√¥ng")
                return downsampled_map_dir
            else:
                self.log_message("‚ö†Ô∏è Kh√¥ng th·ªÉ downsample map, ti·∫øp t·ª•c v·ªõi map g·ªëc")
        elif total_points > self.safe_map_points:
            # Map 2M-5M points - v·∫´n c√≥ th·ªÉ lag, n√™n optimize t·∫•t c·∫£ files
            self.log_message(f"‚ÑπÔ∏è Map c√≥ {total_points:,} points (c√≥ th·ªÉ g√¢y lag nh·∫π)")
            self.log_message("üìâ T·ª± ƒë·ªông optimize t·∫•t c·∫£ files ƒë·ªÉ RViz m∆∞·ª£t h∆°n...")
        
        # Lu√¥n ki·ªÉm tra v√† auto-downsample c√°c file PCD qu√° l·ªõn
        # ƒê·ªÉ ƒë·∫£m b·∫£o RViz m∆∞·ª£t khi ƒë·ªçc t·ª´ng file (ngay c·∫£ khi t·ªïng map < 10M)
        # Truy·ªÅn total_points ƒë·ªÉ n·∫øu map > safe_map_points, downsample t·∫•t c·∫£ files
        optimized_map_dir = self._auto_downsample_large_files(str(map_path), total_map_points=total_points)
        if optimized_map_dir:
            return optimized_map_dir
        
        # Map OK, s·ª≠ d·ª•ng map g·ªëc
        return str(map_path)
    
    def _auto_downsample_large_files(self, map_dir_path, total_map_points=None):
        """
        T·ª± ƒë·ªông downsample c√°c file PCD qu√° l·ªõn (> max_points_per_file) 
        ho·∫∑c t·∫•t c·∫£ c√°c file n·∫øu t·ªïng map > safe_map_points
        ƒë·ªÉ ƒë·∫£m b·∫£o RViz m∆∞·ª£t khi ch·∫°y Localization2
        
        Args:
            map_dir_path: Path ƒë·∫øn map directory
            total_map_points: T·ªïng s·ªë points c·ªßa map (n·∫øu bi·∫øt tr∆∞·ªõc)
        
        Returns:
            str: Path ƒë·∫øn map directory ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (n·∫øu c√≥ file c·∫ßn downsample)
                 None n·∫øu kh√¥ng c√≥ file n√†o c·∫ßn downsample
        """
        if not HAS_OPEN3D:
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists() or not pcd_dir.exists():
            return None
        
        # ƒê·ªçc pose.json ƒë·ªÉ bi·∫øt c√°c file c·∫ßn ki·ªÉm tra
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            return None
        
        # N·∫øu t·ªïng map > safe_map_points, downsample t·∫•t c·∫£ c√°c file (kh√¥ng ch·ªâ file l·ªõn)
        should_downsample_all = total_map_points and total_map_points > self.safe_map_points
        
        # Ki·ªÉm tra t·ª´ng file PCD
        large_files = []
        total_points_checked = 0
        for file_index, _ in enumerate(poses):
            pcd_file = pcd_dir / f"{file_index}.pcd"
            if not pcd_file.exists():
                continue
            
            try:
                # ƒê·ªçc nhanh ƒë·ªÉ ki·ªÉm tra s·ªë points
                pcd = o3d.io.read_point_cloud(str(pcd_file))
                num_points = len(pcd.points)
                total_points_checked += num_points
                
                # N·∫øu t·ªïng map l·ªõn, downsample t·∫•t c·∫£ c√°c file
                # Ho·∫∑c n·∫øu file ri√™ng l·∫ª qu√° l·ªõn, downsample file ƒë√≥
                if should_downsample_all or num_points > self.max_points_per_file:
                    large_files.append((file_index, pcd_file, num_points))
            except:
                continue
        
        # N·∫øu kh√¥ng c√≥ file n√†o c·∫ßn x·ª≠ l√Ω, kh√¥ng c·∫ßn optimize
        if not large_files:
            return None
        
        # C√≥ file c·∫ßn x·ª≠ l√Ω, t·∫°o b·∫£n copy ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
        if should_downsample_all:
            self.log_message(f"üìâ Map c√≥ {total_map_points:,} points > {self.safe_map_points:,}")
            self.log_message(f"   T·ª± ƒë·ªông downsample t·∫•t c·∫£ {len(large_files)} files ƒë·ªÉ RViz m∆∞·ª£t h∆°n...")
        else:
            self.log_message(f"üìâ Ph√°t hi·ªán {len(large_files)} file PCD qu√° l·ªõn (> {self.max_points_per_file:,} points/file)")
            self.log_message("   T·ª± ƒë·ªông downsample c√°c file n√†y ƒë·ªÉ RViz m∆∞·ª£t h∆°n...")
        
        # T·∫°o th∆∞ m·ª•c optimized map
        temp_dir = Path(tempfile.gettempdir()) / "localization2_optimized"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        optimized_map_dir = temp_dir / f"{map_dir.name}_optimized"
        optimized_map_dir.mkdir(exist_ok=True)
        optimized_pcd_dir = optimized_map_dir / "pcd"
        optimized_pcd_dir.mkdir(exist_ok=True)
        
        # Copy pose.json
        shutil.copy2(pose_file, optimized_map_dir / "pose.json")
        
        # X·ª≠ l√Ω t·ª´ng file
        processed_count = 0
        for file_index, original_pcd_file, original_points in large_files:
            try:
                # ƒê·ªçc v√† auto-downsample file (voxel size ƒë·ªông d·ª±a tr√™n s·ªë points)
                pcd, was_downsampled, voxel_size = self._read_pcd_with_auto_downsample(original_pcd_file, preserve_colors=True)
                
                if pcd is None:
                    # Copy file g·ªëc n·∫øu kh√¥ng ƒë·ªçc ƒë∆∞·ª£c
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                    continue
                
                # L∆∞u file ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
                # ƒê·∫£m b·∫£o colors ƒë∆∞·ª£c l∆∞u ƒë√∫ng format (PointXYZRGB n·∫øu c√≥ colors)
                output_file = optimized_pcd_dir / f"{file_index}.pcd"
                # Open3D t·ª± ƒë·ªông detect format d·ª±a tr√™n c√≥ colors hay kh√¥ng
                # write_ascii=False: l∆∞u binary format (nhanh h∆°n, nh·ªè h∆°n)
                # compressed=False: kh√¥ng n√©n ƒë·ªÉ ƒë·∫£m b·∫£o t∆∞∆°ng th√≠ch t·ªët
                success = o3d.io.write_point_cloud(
                    str(output_file),
                    pcd,
                    write_ascii=False,
                    compressed=False
                )
                
                if success:
                    reduction = (1 - len(pcd.points) / original_points) * 100 if original_points > 0 else 0
                    color_status = "‚úÖ RGB" if pcd.has_colors() else "‚ö†Ô∏è No RGB"
                    voxel_info = f" (voxel={voxel_size:.3f}m)" if voxel_size else ""
                    self.log_message(f"   üì¶ File {file_index}.pcd: {original_points:,} ‚Üí {len(pcd.points):,} points ({reduction:.1f}% reduction){voxel_info} {color_status}")
                    processed_count += 1
                else:
                    # Copy file g·ªëc n·∫øu kh√¥ng l∆∞u ƒë∆∞·ª£c
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                    
            except Exception as e:
                # Copy file g·ªëc n·∫øu c√≥ l·ªói
                try:
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                except:
                    pass
                continue
        
        # Copy c√°c file kh√¥ng qu√° l·ªõn t·ª´ map g·ªëc
        for file_index, _ in enumerate(poses):
            if file_index in [f[0] for f in large_files]:
                continue  # ƒê√£ x·ª≠ l√Ω r·ªìi
            
            original_pcd_file = pcd_dir / f"{file_index}.pcd"
            if original_pcd_file.exists():
                try:
                    shutil.copy2(original_pcd_file, optimized_pcd_dir / f"{file_index}.pcd")
                except:
                    pass
        
        if processed_count > 0:
            self.log_message(f"‚úÖ ƒê√£ t·ª± ƒë·ªông downsample {processed_count} file PCD qu√° l·ªõn")
            self.log_message(f"   Optimized map: {optimized_map_dir}")
            return str(optimized_map_dir)
        
        return None
    
    @staticmethod
    def _downsample_single_file(args):
        """
        Worker function ƒë·ªÉ downsample m·ªôt file PCD (d√πng cho multiprocessing)
        Args: (pcd_file_path, output_path, dynamic_voxel_size, max_points_per_file, target_points_per_file, file_downsample_voxel_size)
        Returns: (success, file_index, original_points, downsampled_points, has_colors, error_msg)
        """
        try:
            pcd_file_path, output_path, dynamic_voxel_size, max_points_per_file, target_points_per_file, file_downsample_voxel_size = args
            
            if not HAS_OPEN3D:
                return (False, None, 0, 0, False, "open3d not available")
            
            import numpy as np
            
            # ƒê·ªçc PCD file
            pcd = o3d.io.read_point_cloud(str(pcd_file_path), format='auto')
            if len(pcd.points) == 0:
                return (False, None, 0, 0, False, "Empty point cloud")
            
            original_points = len(pcd.points)
            has_colors = pcd.has_colors()
            
            # Auto-downsample n·∫øu file qu√° l·ªõn
            if original_points > max_points_per_file:
                if has_colors:
                    colors = np.asarray(pcd.colors)
                    if colors.max() > 1.0 and colors.max() <= 255.0:
                        pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)
                
                # T√≠nh voxel size ƒë·ªông
                reduction_ratio = original_points / target_points_per_file
                file_voxel_size = file_downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                file_voxel_size = max(0.05, min(0.5, file_voxel_size))
                
                pcd = pcd.voxel_down_sample(voxel_size=file_voxel_size)
            
            # Downsample th√™m v·ªõi voxel size c·ªßa map
            if len(pcd.points) > 0:
                pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
            
            downsampled_points = len(pcd.points)
            
            # L∆∞u file
            success = o3d.io.write_point_cloud(
                str(output_path),
                pcd,
                write_ascii=False,
                compressed=False
            )
            
            if success:
                return (True, None, original_points, downsampled_points, pcd.has_colors(), None)
            else:
                return (False, None, original_points, 0, False, "Failed to write file")
                
        except Exception as e:
            return (False, None, 0, 0, False, str(e))
    
    def downsample_map_tiles(self, map_dir_path, total_map_points=None):
        """
        Downsample t·∫•t c·∫£ PCD tiles trong map directory (song song ƒë·ªÉ nhanh h∆°n)
        Voxel size ƒë∆∞·ª£c t√≠nh ƒë·ªông d·ª±a tr√™n t·ªïng s·ªë points ƒë·ªÉ ƒë·∫£m b·∫£o gi·∫£m ƒë·ªß
        """
        if not HAS_OPEN3D:
            self.log_message("‚ùå open3d kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. Kh√¥ng th·ªÉ downsample map.")
            self.log_message("üí° C√†i ƒë·∫∑t: pip3 install open3d")
            return None
        
        map_dir = Path(map_dir_path)
        pose_file = map_dir / "pose.json"
        pcd_dir = map_dir / "pcd"
        
        if not pose_file.exists() or not pcd_dir.exists():
            self.log_message("‚ùå Map directory kh√¥ng h·ª£p l·ªá")
            return None
        
        # T√≠nh to√°n voxel size ƒë·ªông d·ª±a tr√™n t·ªïng s·ªë points
        # Map c√†ng l·ªõn ‚Üí voxel size c√†ng l·ªõn ‚Üí downsample c√†ng nhi·ªÅu
        if total_map_points:
            # Target: gi·∫£m xu·ªëng ~2-3M points ƒë·ªÉ RViz r·∫•t m∆∞·ª£t (gi·∫£m t·ª´ 4M)
            target_points = 2_500_000  # 2.5M points target (gi·∫£m t·ª´ 4M)
            if total_map_points > target_points:
                reduction_ratio = total_map_points / target_points
                # Cube root v√¨ volume t·ª∑ l·ªá v·ªõi size^3
                dynamic_voxel_size = self.downsample_voxel_size * (reduction_ratio ** (1.0/3.0))
                # Gi·ªõi h·∫°n trong kho·∫£ng h·ª£p l√Ω (0.18m - 0.35m) - tƒÉng ƒë·ªÉ downsample nhi·ªÅu h∆°n
                dynamic_voxel_size = max(0.18, min(0.35, dynamic_voxel_size))
            else:
                dynamic_voxel_size = self.downsample_voxel_size
        else:
            dynamic_voxel_size = self.downsample_voxel_size
        
        # T·∫°o th∆∞ m·ª•c downsampled map
        temp_dir = Path(tempfile.gettempdir()) / "localization2_downsampled"
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        downsampled_map_dir = temp_dir / f"{map_dir.name}_downsampled"
        downsampled_map_dir.mkdir(exist_ok=True)
        downsampled_pcd_dir = downsampled_map_dir / "pcd"
        downsampled_pcd_dir.mkdir(exist_ok=True)
        
        # Copy pose.json
        shutil.copy2(pose_file, downsampled_map_dir / "pose.json")
        
        # ƒê·ªçc pose.json
        poses = []
        try:
            with open(pose_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    parts = line.split()
                    if len(parts) >= 7:
                        try:
                            tx, ty, tz = float(parts[0]), float(parts[1]), float(parts[2])
                            w, x, y, z = float(parts[3]), float(parts[4]), float(parts[5]), float(parts[6])
                            poses.append((tx, ty, tz, w, x, y, z))
                        except ValueError:
                            continue
        except Exception as e:
            self.log_message(f"‚ùå L·ªói khi ƒë·ªçc pose.json: {e}")
            return None
        
        self.log_message(f"üìâ ƒêang downsample {len(poses)} PCD tiles (voxel_size={dynamic_voxel_size:.3f}m)...")
        
        # Chu·∫©n b·ªã danh s√°ch files ƒë·ªÉ x·ª≠ l√Ω song song
        files_to_process = []
        for file_index, _ in enumerate(poses):
            pcd_file = pcd_dir / f"{file_index}.pcd"
            if pcd_file.exists():
                downsampled_pcd_file = downsampled_pcd_dir / f"{file_index}.pcd"
                files_to_process.append((
                    str(pcd_file),
                    str(downsampled_pcd_file),
                    dynamic_voxel_size,
                    self.max_points_per_file,
                    self.target_points_per_file,
                    self.file_downsample_voxel_size
                ))
        
        # S·ª≠ d·ª•ng multiprocessing ƒë·ªÉ x·ª≠ l√Ω song song (nhanh h∆°n nhi·ªÅu)
        loaded_count = 0
        failed_count = 0
        total_points_before = 0
        total_points_after = 0
        has_rgb_count = 0
        
        if HAS_MULTIPROCESSING and len(files_to_process) > 10:
            # S·ª≠ d·ª•ng multiprocessing n·∫øu c√≥ nhi·ªÅu files (>10)
            num_workers = min(cpu_count(), 8)  # T·ªëi ƒëa 8 workers ƒë·ªÉ tr√°nh qu√° t·∫£i
            self.log_message(f"   üöÄ S·ª≠ d·ª•ng {num_workers} workers ƒë·ªÉ downsample song song (nhanh h∆°n ~{num_workers}x)...")
            
            try:
                with Pool(processes=num_workers) as pool:
                    results = pool.map(self._downsample_single_file, files_to_process)
                
                # X·ª≠ l√Ω k·∫øt qu·∫£
                for i, (success, _, orig_points, down_points, has_colors, error_msg) in enumerate(results):
                    if success:
                        loaded_count += 1
                        total_points_before += orig_points
                        total_points_after += down_points
                        if has_colors:
                            has_rgb_count += 1
                        
                        # Progress indicator
                        if loaded_count % 50 == 0 or loaded_count == len(files_to_process):
                            reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
                            self.log_message(f"  üì¶ ƒê√£ downsample {loaded_count}/{len(files_to_process)} tiles, "
                                           f"{total_points_after:,} points ({reduction:.1f}% reduction)...")
                    else:
                        failed_count += 1
                        if failed_count <= 5 and error_msg:
                            self.log_message(f"  ‚ö†Ô∏è  L·ªói: {error_msg}")
            except Exception as e:
                self.log_message(f"  ‚ö†Ô∏è  L·ªói multiprocessing, chuy·ªÉn sang x·ª≠ l√Ω tu·∫ßn t·ª±: {e}")
                # Reset counters for sequential processing
                loaded_count = 0
                failed_count = 0
                total_points_before = 0
                total_points_after = 0
                has_rgb_count = 0
        
        # X·ª≠ l√Ω tu·∫ßn t·ª± n·∫øu kh√¥ng d√πng multiprocessing ho·∫∑c c√≥ l·ªói
        use_sequential = not (HAS_MULTIPROCESSING and len(files_to_process) > 10) or loaded_count == 0
        if use_sequential:
            for file_index, (tx, ty, tz, w, x, y, z) in enumerate(poses):
                pcd_file = pcd_dir / f"{file_index}.pcd"
                downsampled_pcd_file = downsampled_pcd_dir / f"{file_index}.pcd"
                
                if not pcd_file.exists():
                    failed_count += 1
                    continue
                
                try:
                    # ƒê·ªçc PCD file v·ªõi auto-downsample n·∫øu file qu√° l·ªõn
                    pcd, was_auto_downsampled, voxel_size = self._read_pcd_with_auto_downsample(pcd_file, preserve_colors=True)
                    
                    if pcd is None or len(pcd.points) == 0:
                        failed_count += 1
                        continue
                    
                    # ƒê·∫øm points g·ªëc
                    if was_auto_downsampled:
                        try:
                            original_pcd = o3d.io.read_point_cloud(str(pcd_file))
                            points_before_file = len(original_pcd.points) if original_pcd else len(pcd.points)
                        except:
                            points_before_file = int(len(pcd.points) * 1.5)
                    else:
                        points_before_file = len(pcd.points)
                    
                    total_points_before += points_before_file
                    has_colors = pcd.has_colors()
                    
                    # Downsample th√™m v·ªõi voxel size ƒë·ªông
                    downsampled_pcd = pcd.voxel_down_sample(voxel_size=dynamic_voxel_size)
                    total_points_after += len(downsampled_pcd.points)
                    
                    # ƒê·∫£m b·∫£o colors ƒë∆∞·ª£c preserve
                    if has_colors and not downsampled_pcd.has_colors():
                        import numpy as np
                        if HAS_SCIPY and cKDTree:
                            original_points = np.asarray(pcd.points)
                            original_colors = np.asarray(pcd.colors)
                            downsampled_points = np.asarray(downsampled_pcd.points)
                            tree = cKDTree(original_points)
                            _, indices = tree.query(downsampled_points, k=1)
                            downsampled_colors = original_colors[indices]
                            downsampled_pcd.colors = o3d.utility.Vector3dVector(downsampled_colors)
                    
                    # L∆∞u file
                    success = o3d.io.write_point_cloud(
                        str(downsampled_pcd_file), 
                        downsampled_pcd, 
                        write_ascii=False,
                        compressed=False
                    )
                    if not success:
                        failed_count += 1
                        continue
                    
                    loaded_count += 1
                    if downsampled_pcd.has_colors():
                        has_rgb_count += 1
                    
                    # Progress indicator
                    if loaded_count % 50 == 0 or loaded_count == len(poses):
                        reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
                        self.log_message(f"  üì¶ ƒê√£ downsample {loaded_count}/{len(poses)} tiles, "
                                       f"{total_points_after:,} points ({reduction:.1f}% reduction)...")
                        
                except Exception as e:
                    failed_count += 1
                    if failed_count <= 5:
                        self.log_message(f"  ‚ö†Ô∏è  L·ªói khi downsample {pcd_file.name}: {e}")
                    continue
        
        if loaded_count == 0:
            self.log_message("‚ùå Kh√¥ng downsample ƒë∆∞·ª£c tile n√†o")
            return None
        
        if failed_count > 0:
            self.log_message(f"‚ö†Ô∏è  {failed_count} tiles kh√¥ng downsample ƒë∆∞·ª£c")
        
        reduction = (1 - total_points_after / total_points_before) * 100 if total_points_before > 0 else 0
        
        # Ki·ªÉm tra xem c√≥ colors trong downsampled map kh√¥ng
        sample_pcd = o3d.io.read_point_cloud(str(downsampled_pcd_dir / "0.pcd"))
        has_rgb = sample_pcd.has_colors() if sample_pcd and len(sample_pcd.points) > 0 else False
        
        self.log_message(f"‚úÖ ƒê√£ downsample {loaded_count} tiles")
        self.log_message(f"   Points: {total_points_before:,} ‚Üí {total_points_after:,} ({reduction:.1f}% reduction)")
        if has_rgb_count > 0:
            rgb_percent = (has_rgb_count / loaded_count) * 100 if loaded_count > 0 else 0
            self.log_message(f"   ‚úÖ {has_rgb_count}/{loaded_count} files c√≥ RGB colors ({rgb_percent:.1f}%) - map s·∫Ω hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß m√†u s·∫Øc")
        else:
            self.log_message(f"   ‚ö†Ô∏è No RGB colors detected - map s·∫Ω hi·ªÉn th·ªã m√†u v√†ng m·∫∑c ƒë·ªãnh")
        self.log_message(f"   Downsampled map: {downsampled_map_dir}")
        
        return str(downsampled_map_dir)
    
    def _start_localization2_with_map(self, map_dir):
        """Start Localization2 v·ªõi map directory ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω"""
        try:
            # Make script executable
            os.chmod(self.script_path, 0o755)
            
            # Start localization2
            cmd = [str(self.script_path), map_dir]
            self.log_message(f"Executing: {' '.join(cmd)}")
            
            self.localization_process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True,
                cwd=str(self.project_root)
            )
            
            # Start ROS listener
            self.start_ros_listener()
            
            # Read output v√† filter warnings kh√¥ng c·∫ßn thi·∫øt
            warnings_to_filter = [
                "Failed to find match for field 'normal_x'",
                "Failed to find match for field 'normal_y'",
                "Failed to find match for field 'normal_z'",
                "Failed to find match for field 'intensity'",
                "Failed to find match for field 'curvature'",
            ]
            
            warning_count = {}
            for warning in warnings_to_filter:
                warning_count[warning] = 0
            
            warning_shown = False  # Ch·ªâ hi·ªÉn th·ªã warning message m·ªôt l·∫ßn
            
            for line in iter(self.localization_process.stdout.readline, ''):
                if not line:
                    break
                
                line_stripped = line.strip()
                
                # Filter warnings v·ªÅ missing fields (ch·ªâ hi·ªÉn th·ªã summary)
                should_filter = False
                matched_warning = None
                for warning in warnings_to_filter:
                    if warning in line_stripped:
                        warning_count[warning] += 1
                        should_filter = True
                        matched_warning = warning
                        break
                
                if not should_filter:
                    self.log_message(line_stripped)
                elif not warning_shown:
                    # Hi·ªÉn th·ªã warning ƒë·∫ßu ti√™n v·ªõi note
                    self.log_message(f"‚ö†Ô∏è PCD files missing some fields (normal_x, normal_y, intensity, etc.) - this is normal for PointXYZRGB format. Warnings will be suppressed.")
                    warning_shown = True
            
            # Hi·ªÉn th·ªã summary n·∫øu c√≥ nhi·ªÅu warnings
            total_warnings = sum(warning_count.values())
            if total_warnings > 10:
                self.log_message(f"‚ÑπÔ∏è Suppressed {total_warnings} PCD field warnings (normal for PointXYZRGB format)")
            
            # Process finished
            return_code = self.localization_process.wait()
            self.localization_process = None
            
            if return_code == 0:
                self.log_message("‚úÖ Localization2 finished successfully")
            else:
                self.log_message(f"‚ö†Ô∏è Localization2 finished with return code: {return_code}")
            
        except Exception as e:
            self.log_message(f"‚ùå Error starting Localization2: {e}")
        finally:
            self._reset_ui_state()
    
    def stop_localization2(self):
        """Stop Localization2"""
        self.log_message("Stopping Localization2...")
        
        # Stop ROS listener
        self.stop_ros_listener()
        
        # Stop process
        if self.localization_process:
            try:
                if platform.system() == "Windows":
                    self.localization_process.terminate()
                else:
                    os.kill(self.localization_process.pid, signal.SIGTERM)
                
                # Wait a bit
                time.sleep(2)
                
                # Force kill if still running
                if self.localization_process.poll() is None:
                    if platform.system() == "Windows":
                        self.localization_process.kill()
                    else:
                        os.kill(self.localization_process.pid, signal.SIGKILL)
                
                self.log_message("‚úÖ Localization2 stopped")
            except Exception as e:
                self.log_message(f"‚ö†Ô∏è Error stopping process: {e}")
        
        # Kill any remaining localization processes
        try:
            if platform.system() != "Windows":
                subprocess.run(['pkill', '-f', 'localization'], timeout=3, capture_output=True)
                subprocess.run(['pkill', '-f', 'fast_lio_localization'], timeout=3, capture_output=True)
        except:
            pass
        
        self._reset_ui_state()
    
    def _reset_ui_state(self):
        """Reset UI state"""
        self.is_localization_running = False
        self.start_button.config(state=tk.NORMAL)
        self.stop_button.config(state=tk.DISABLED)
        self.status_var.set("Stopped")
    
    def start_ros_listener(self):
        """Start ROS2 listener for localization data"""
        if not ROS2_AVAILABLE:
            self.log_message("‚ö†Ô∏è ROS2 not available, cannot subscribe to /Odometry")
            return
        
        if self.is_ros_running:
            return
        
        def ros_thread():
            try:
                if not rclpy.ok():
                    rclpy.init()
                
                self.ros_node = LocalizationListenerNode(self)
                self.ros_executor = MultiThreadedExecutor()
                self.ros_executor.add_node(self.ros_node)
                
                self.is_ros_running = True
                self.log_message("‚úÖ Started ROS2 listener for /Odometry topic")
                
                # Run executor
                self.ros_executor.spin()
            except Exception as e:
                self.log_message(f"‚ùå Error in ROS2 listener: {e}")
            finally:
                self.is_ros_running = False
        
        self.ros_thread = threading.Thread(target=ros_thread, daemon=True)
        self.ros_thread.start()
    
    def stop_ros_listener(self):
        """Stop ROS2 listener"""
        if not self.is_ros_running:
            return
        
        try:
            if self.ros_executor:
                self.ros_executor.shutdown()
            if self.ros_node:
                self.ros_node.destroy_node()
            if rclpy.ok():
                rclpy.shutdown()
            self.log_message("‚úÖ Stopped ROS2 listener")
        except Exception as e:
            self.log_message(f"‚ö†Ô∏è Error stopping ROS2 listener: {e}")
        finally:
            self.is_ros_running = False
    
    def update_localization_data(self, msg):
        """Update localization data from ROS message"""
        try:
            # Extract data from message
            pos = msg.pose.pose.position
            orient = msg.pose.pose.orientation
            vel = msg.twist.twist.linear
            
            # Update UI (must be done in main thread)
            self.after(0, lambda: self._update_ui_data(
                pos.x, pos.y, pos.z,
                orient.x, orient.y, orient.z, orient.w,
                vel.x, vel.y, vel.z,
                msg.header.stamp
            ))
        except Exception as e:
            if ROS2_AVAILABLE and self.ros_node:
                self.ros_node.get_logger().error(f'Error updating localization data: {e}')
    
    def _update_ui_data(self, px, py, pz, ox, oy, oz, ow, vx, vy, vz, stamp):
        """Update UI with localization data (called from main thread)"""
        try:
            self.position_var.set(f"({px:.3f}, {py:.3f}, {pz:.3f})")
            self.orientation_var.set(f"({ox:.3f}, {oy:.3f}, {oz:.3f}, {ow:.3f})")
            self.velocity_var.set(f"({vx:.3f}, {vy:.3f}, {vz:.3f})")
            
            # Convert timestamp
            if hasattr(stamp, 'sec') and hasattr(stamp, 'nanosec'):
                dt = datetime.fromtimestamp(stamp.sec + stamp.nanosec / 1e9)
                self.timestamp_var.set(dt.strftime("%H:%M:%S.%f")[:-3])
            else:
                self.timestamp_var.set("N/A")
        except Exception as e:
            self.log_message(f"Error updating UI: {e}")

